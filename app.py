import streamlit as st
import pandas as pd
import os
import re
from datetime import datetime
import io
import zipfile
import tempfile
from openpyxl import Workbook
from openpyxl.utils.dataframe import dataframe_to_rows
import plotly.express as px
from uuid import uuid4
from typing import Callable, List, Any, Dict

# === Concurrency-safe session + helpers ===
if "SID" not in st.session_state:
    st.session_state.SID = uuid4().hex[:6]

def unique_tmp_path(suggest_name: str, default_ext: str = ".xlsx") -> str:
    base, ext = os.path.splitext(suggest_name or f"result{default_ext}")
    ext = ext or default_ext
    return os.path.join("/tmp", f"{base}_{st.session_state.SID}_{uuid4().hex[:8]}{ext}")

@st.cache_data(ttl=1800, show_spinner=False)
def _read_excel_cached(file_or_path, sheet_name=0, engine=None):
    return pd.read_excel(file_or_path, sheet_name=sheet_name, engine=engine)

# App configuration
APP_CONFIG = {
    "app_title": "å¸‚åœºæ´å¯Ÿå°ç¨‹åº",
    "author": "æµ·ç¿¼IDCå›¢é˜Ÿ",
    "version": "v1.2.0",
    "contact": "idc@oceanwing.com",
    "company": "Anker Oceanwing Inc."
}

# === Shared UI/render helpers ===
def render_app_header(emoji_title: str, subtitle: str):
    st.markdown(f"""
    <div style="background: linear-gradient(135deg, #00a6e4 0%, #0088c2 100%); padding: 2rem; border-radius: 10px; margin-bottom: 2rem; box-shadow: 0 4px 6px rgba(0,0,0,0.1);">
        <h2 style="color: white; margin: 0; display: flex; align-items: center;">
            {emoji_title}
        </h2>
        <p style="color: rgba(255,255,255,0.9); margin-top: 0.5rem;">{subtitle}</p>
    </div>
    """, unsafe_allow_html=True)

def get_timestamp() -> str:
    return datetime.now().strftime("%Y-%m-%d_%H-%M-%S")

def save_df_to_buffer(df: pd.DataFrame) -> io.BytesIO:
    buffer = io.BytesIO()
    df.to_excel(buffer, index=False, engine="openpyxl")
    buffer.seek(0)
    return buffer

def save_workbook_to_buffer(wb: Workbook) -> io.BytesIO:
    buffer = io.BytesIO()
    wb.save(buffer)
    buffer.seek(0)
    return buffer

def render_download_section(
    buffer: io.BytesIO,
    file_name: str,
    mime_type: str,
    download_label: str,
    key_prefix: str,
    has_save: bool = False,
    save_func: Callable[[], None] | None = None,
    save_path: str | None = None,
):
    if has_save:
        col_d, col_s = st.columns(2)
        with col_d:
            st.download_button(
                label=download_label,
                data=buffer,
                file_name=file_name,
                mime=mime_type,
                key=f"{key_prefix}_download",
                use_container_width=True,
            )
        with col_s:
            if st.checkbox("ğŸ’¾ åŒæ—¶ä¿å­˜åˆ° /tmp ç›®å½•", key=f"{key_prefix}_save"):
                if save_func:
                    save_func()
                st.info(f"ğŸ“ æ–‡ä»¶å·²ä¿å­˜åˆ° {save_path}")
    else:
        st.download_button(
            label=download_label,
            data=buffer,
            file_name=file_name,
            mime=mime_type,
            key=f"{key_prefix}_download",
            use_container_width=True,
        )

# === Shared ZIP processors ===
def read_file_merge(file_path: str) -> pd.DataFrame | None:
    ext = os.path.splitext(file_path)[1].lower()
    if ext == ".csv":
        return pd.read_csv(file_path)
    engine = "openpyxl" if ext == ".xlsx" else "xlrd" if ext == ".xls" else None
    if engine:
        return _read_excel_cached(file_path, engine=engine)
    return None

def read_file_clean(file_path: str) -> pd.DataFrame | None:
    ext = os.path.splitext(file_path)[1].lower()
    if ext == ".csv":
        return pd.read_csv(file_path, header=None)
    engine = "openpyxl" if ext == ".xlsx" else "xlrd" if ext == ".xls" else None
    if engine:
        return pd.read_excel(file_path, header=None, engine=engine)
    return None

def write_processed_file(df: pd.DataFrame, path: str, ext: str):
    if ext == ".csv":
        df.to_csv(path, index=False)
    else:
        df.to_excel(path, index=False, engine="openpyxl")

def process_zip_files(
    uploaded_file,
    read_cb: Callable[[str], pd.DataFrame | None],
    process_cb: Callable[[pd.DataFrame, str, str], Any],
) -> List[Any]:
    with tempfile.TemporaryDirectory() as temp_dir:
        zip_path = os.path.join(temp_dir, uploaded_file.name)
        with open(zip_path, "wb") as f:
            f.write(uploaded_file.getbuffer())
        with zipfile.ZipFile(zip_path, "r") as z:
            z.extractall(temp_dir)
        files = [f for f in os.listdir(temp_dir) if f.lower().endswith((".xlsx", ".xls", ".csv"))]
        if not files:
            st.warning("ğŸ“‚ å‹ç¼©æ–‡ä»¶ä¸­æœªæ‰¾åˆ°ä»»ä½• Excel æˆ– CSV æ–‡ä»¶")
            return []
        results = []
        pb = st.progress(0)
        status = st.empty()
        for i, f in enumerate(files):
            status.text(f"æ­£åœ¨å¤„ç†: {f} ({i+1}/{len(files)})")
            fp = os.path.join(temp_dir, f)
            try:
                df = read_cb(fp)
                if df is None:
                    raise ValueError("ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼")
                results.append(process_cb(df, f, temp_dir))
            except Exception as e:
                st.error(f"âŒ å¤„ç†æ–‡ä»¶ {f} å¤±è´¥: {e}")
            pb.progress((i + 1) / len(files))
        status.empty()
        pb.empty()
        return results

# å¤„ç†ä»·æ ¼åˆ—
def process_price_columns(df):
    df = df.copy()
    price_pattern = re.compile(r'\$(\d+\.\d+)(?:\s*-\s*\$\d+\.\d+)?')
    def extract_price(price_str):
        if not isinstance(price_str, str):
            return price_str
        price_str = price_str.replace(',', '')
        match = price_pattern.match(price_str)
        return float(match.group(1)) if match else float(price_str.replace('$', ''))
    price_columns = [col for col in df.columns if 'å”®ä»·' in col]
    for column in price_columns:
        df[column] = df[column].apply(extract_price)
    return df

# åˆå¹¶æ•°æ®è¡¨æ ¼åŠŸèƒ½
def merge_data_app():
    render_app_header("ğŸ“Š MI/SI - åˆå¹¶æ•°æ®è¡¨æ ¼", "å°†å¤šä¸ªExcelæ–‡ä»¶åˆå¹¶ä¸ºä¸€ä¸ªç»Ÿä¸€çš„æ•°æ®è¡¨æ ¼")
    col1, col2 = st.columns([2, 1])
    with col1:
        uploaded_file = st.file_uploader(
            "é€‰æ‹©ä¸€ä¸ª .zip æ–‡ä»¶(åŒ…å«éœ€è¦åˆå¹¶çš„ Excel æ–‡ä»¶)",
            type=["zip"],
            accept_multiple_files=False,
            key="merge_files",
            help="æ”¯æŒåŒ…å«.xlsxã€.xlsã€.csvæ ¼å¼çš„ZIPå‹ç¼©åŒ…",
        )
    with col2:
        save_filename = st.text_input(
            "è¾“å‡ºæ–‡ä»¶å",
            value="merged_output.xlsx",
            key="merge_save",
            help="è¯·è¾“å…¥åˆå¹¶åçš„æ–‡ä»¶å",
        )
    st.divider()
    execute_btn = st.button("ğŸš€ å¼€å§‹åˆå¹¶", key="merge_button", use_container_width=True)
    if execute_btn:
        if not uploaded_file or not save_filename:
            st.warning("âš ï¸ è¯·ç¡®ä¿å·²é€‰æ‹© .zip æ–‡ä»¶å¹¶è¾“å…¥æ–‡ä»¶å")
            return
        with st.spinner("ğŸ”„ æ­£åœ¨å¤„ç†æ–‡ä»¶ï¼Œè¯·ç¨å€™..."):
            save_path = unique_tmp_path(save_filename)
            def cb_merge(df, fname, _):
                df["æ—¶é—´"] = os.path.splitext(fname)[0]
                return process_price_columns(df)
            df_list = process_zip_files(uploaded_file, read_file_merge, cb_merge)
            if not df_list:
                return
            status = st.empty()
            prog = st.progress(0)
            status.text("æ­£åœ¨åˆå¹¶æ•°æ®...")
            merged_df = pd.concat(df_list, ignore_index=True)
            merged_df = merged_df.loc[:, ~merged_df.columns.duplicated()]
            prog.progress(1.0)
            status.text("åˆå¹¶å®Œæˆ")
            status.empty()
            prog.empty()
            buffer = save_df_to_buffer(merged_df)
            st.success(f"âœ… æˆåŠŸåˆå¹¶ {len(df_list)} ä¸ªæ–‡ä»¶ï¼Œå…± {len(merged_df)} è¡Œæ•°æ®")
            save_func = lambda: merged_df.to_excel(save_path, index=False, engine="openpyxl")
            render_download_section(
                buffer,
                os.path.basename(save_filename),
                "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                "ğŸ“¥ ä¸‹è½½åˆå¹¶åçš„æ–‡ä»¶",
                "merged",
                has_save=True,
                save_func=save_func,
                save_path=save_path,
            )

# æœç´¢æµé‡æ´å¯Ÿï¼ˆæºæ•°æ®ï¼‰
def analyze_search_rows(df: pd.DataFrame, params: List[tuple]):
    punct = str.maketrans("", "", '!"#$%&\'()*+,-./:;<=>?@[\\]^_`{|}~')
    brands = df["å“ç‰Œåç§°"].dropna().unique()
    for p, _ in params:
        df[p] = ""
    df["å“ç‰Œ"] = ""
    df["ç‰¹æ€§å‚æ•°"] = ""
    results = []
    brand_words = []
    pb = st.progress(0)
    status = st.empty()
    for idx, row in df.iterrows():
        status.text(f"æ­£åœ¨åˆ†æç¬¬ {idx+1}/{len(df)} æ¡æ•°æ®...")
        sword = str(row["æœç´¢è¯"]).lower()
        vol = row["æœç´¢é‡"] if pd.notna(row["æœç´¢é‡"]) else 0
        m_brands = []
        for b in brands:
            b_low = str(b).lower()
            if len(b_low) <= 5:
                if re.search(rf"\b{re.escape(b_low)}\b", sword):
                    m_brands.append(b_low)
            else:
                norms = [
                    b_low,
                    b_low.translate(punct),
                    b_low.replace(" ", ""),
                    b_low.translate(punct).replace(" ", ""),
                ]
                if any(n in sword for n in norms):
                    m_brands.append(b_low)
        df.at[idx, "å“ç‰Œ"] = ",".join(set(m_brands))
        m_params = []
        for p_name, p_vals in params:
            m_vals = [str(v).lower() for v in p_vals if str(v).lower() in sword]
            df.at[idx, p_name] = ",".join(set(m_vals))
            m_params.extend(m_vals)
        df.at[idx, "ç‰¹æ€§å‚æ•°"] = ",".join(set(m_params))
        if m_brands:
            results.append("Branded KWs")
            for b in set(m_brands):
                brand_words.append({"å“ç‰Œåç§°": b, "æœç´¢é‡": vol})
        else:
            results.append("Non-Branded KWs")
        pb.progress((idx + 1) / len(df))
    status.empty()
    pb.empty()
    df["è¯æ€§"] = results
    return df, results

def search_insight_app():
    render_app_header("ğŸ” SI - æœç´¢æµé‡æ´å¯Ÿ", "åˆ†ææœç´¢å…³é”®è¯ï¼Œè¯†åˆ«å“ç‰Œè¯ä¸éå“ç‰Œè¯")
    st.markdown("#### ğŸ“‹ æ­¥éª¤ 1: ä¸‹è½½æ•°æ®æ¨¡æ¿")
    tmpl = pd.DataFrame(columns=["æœç´¢è¯", "æœç´¢é‡", "å“ç‰Œåç§°"])
    buf = io.BytesIO()
    tmpl.to_excel(buf, index=False)
    buf.seek(0)
    st.download_button(
        "ğŸ“¥ ä¸‹è½½Excelæ¨¡æ¿",
        buf,
        "template.xlsx",
        "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        key="download_template",
        use_container_width=True,
    )
    st.divider()
    st.markdown("#### ğŸ“¤ æ­¥éª¤ 2: ä¸Šä¼ å¡«å†™å¥½çš„æ•°æ®æ–‡ä»¶")
    col1, col2 = st.columns([2, 1])
    with col1:
        uploaded_file = st.file_uploader("é€‰æ‹©æ•°æ®æ–‡ä»¶", type=["xlsx", "xls"], key="data_file")
    with col2:
        save_filename = st.text_input("è¾“å‡ºæ–‡ä»¶å", "search_insight_result.xlsx", key="save_folder")
    st.divider()
    st.markdown("#### âš™ï¸ æ­¥éª¤ 3: è¾“å…¥äº§å“å‚æ•°(å¯é€‰)")
    col1, col2 = st.columns(2)
    with col1:
        param_names = st.text_input("å‚æ•°å(ç”¨é€—å·åˆ†éš”)", placeholder="ä¾‹å¦‚: é¢œè‰²,å°ºå¯¸,æè´¨", key="param_names")
    with col2:
        param_values = st.text_area(
            "å…·ä½“å‚æ•°(æ¯è¡Œä¸€ä¸ªå‚æ•°ç»„,ç”¨é€—å·åˆ†éš”)",
            placeholder="ä¾‹å¦‚:\nçº¢,è“,ç»¿\nå°,ä¸­,å¤§",
            key="param_values",
            height=100,
        )
    st.divider()
    execute_btn = st.button("ğŸš€ å¼€å§‹åˆ†æ", key="execute_button", use_container_width=True)
    if execute_btn:
        if not uploaded_file or not save_filename:
            st.warning("âš ï¸ è¯·ç¡®ä¿å·²ä¸Šä¼ æ•°æ®æ–‡ä»¶å¹¶è¾“å…¥è¾“å‡ºæ–‡ä»¶å")
            return
        with st.spinner("ğŸ”„ æ­£åœ¨åˆ†ææ•°æ®ï¼Œè¯·ç¨å€™..."):
            save_path = unique_tmp_path(save_filename)
            df = _read_excel_cached(uploaded_file)
            if df.empty:
                st.warning("ğŸ“‚ ä¸Šä¼ çš„æ–‡ä»¶ä¸ºç©ºï¼Œè¯·æ£€æŸ¥æ•°æ®æ–‡ä»¶")
                return
            p_params = []
            if param_names and param_values:
                names = [n.strip() for n in re.split(r"[,\uff0c]", param_names) if n.strip()]
                vals = []
                for line in param_values.split("\n"):
                    vs = [v.strip() for v in re.split(r"[,\uff0c]", line) if v.strip()]
                    if vs:
                        vals.append(vs)
                p_params = list(zip(names, vals)) if len(names) == len(vals) else []
            df, kw_types = analyze_search_rows(df, p_params)
            branded = kw_types.count("Branded KWs")
            non_branded = len(kw_types) - branded
            status = st.empty()
            prog = st.progress(0)
            status.text("æ­£åœ¨ä¿å­˜åˆ°Excel...")
            prog.progress(0.5)
            wb = Workbook()
            if "Sheet" in wb.sheetnames:
                wb.remove(wb["Sheet"])
            ws = wb.create_sheet("æºæ•°æ®")
            for r in dataframe_to_rows(df, index=False, header=True):
                ws.append(r)
            prog.progress(1.0)
            status.text("ä¿å­˜å®Œæˆ")
            status.empty()
            prog.empty()
            buffer = save_workbook_to_buffer(wb)
            ts = get_timestamp()
            out_name = f"result_{ts}.xlsx"
            out_path = os.path.join("/tmp", out_name)
            st.success(f"âœ… åˆ†æå®Œæˆ! å“ç‰Œè¯: {branded} æ¡ | éå“ç‰Œè¯: {non_branded} æ¡")
            save_func = lambda: wb.save(out_path)
            render_download_section(
                buffer,
                out_name,
                "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                "ğŸ“¥ ä¸‹è½½å¤„ç†ç»“æœ",
                "result",
                has_save=True,
                save_func=save_func,
                save_path=out_path,
            )

# å¯è§†åŒ–å…±äº«
def aggregate_top_n(df, value_col, name_col, top_n=10):
    df = df.copy()
    df[name_col] = df[name_col].astype(str)
    df = df.sort_values(by=value_col, ascending=False).reset_index(drop=True)
    if len(df) > top_n:
        top_df = df.iloc[:top_n]
        others = df.iloc[top_n:][value_col].sum()
        others_row = pd.DataFrame([{name_col: "Others", value_col: others}])
        df = pd.concat([top_df[[name_col, value_col]], others_row], ignore_index=True)
    return df[[name_col, value_col]]

def pie_chart(df, value_col, name_col, title):
    df = df.copy()
    df[name_col] = df[name_col].astype(str)
    df = df.sort_values(by=value_col, ascending=False).reset_index(drop=True)
    if "Others" in df[name_col].values:
        order = [n for n in df[name_col] if n != "Others"] + ["Others"]
        df[name_col] = pd.Categorical(df[name_col], categories=order, ordered=True)
    palette = [
        "#4C8EDA", "#FFA14E", "#F25C5C", "#6BD0C1", "#58C27D", "#F7C948",
        "#B685D6", "#FF90B3", "#BC8D6E", "#C9C9C9", "#81D3EB",
    ]
    fig = px.pie(
        df,
        values=value_col,
        names=name_col,
        title=title,
        color_discrete_sequence=palette,
    )
    fig.update_traces(textinfo="label+percent", sort=False)
    fig.update_layout(
        height=900,
        legend=dict(orientation="v", x=0.8, y=0.5, font=dict(size=16)),
        margin=dict(l=20, r=150, t=50, b=50),
        font=dict(size=16),
    )
    st.plotly_chart(fig, use_container_width=True)

def search_insight_viz_app():
    render_app_header("ğŸ“ˆ SI - æœç´¢æµé‡æ´å¯Ÿ: èšåˆå’Œå¯è§†åŒ–", "ç”Ÿæˆå¤šç»´åº¦æ•°æ®åˆ†ææŠ¥è¡¨å’Œå¯è§†åŒ–å›¾è¡¨")
    col1, col2 = st.columns([2, 1])
    with col1:
        uploaded_file = st.file_uploader(
            "é€‰æ‹©åŒ…å«æºæ•°æ®çš„ Excel æ–‡ä»¶(å®Œæˆæ£€æŸ¥ç¡®è®¤æ— è¯¯)",
            type=["xlsx", "xls"],
            key="viz_data_file",
        )
    with col2:
        save_filename = st.text_input("è¾“å‡ºæ–‡ä»¶å", "viz_result.xlsx", key="viz_save_folder")
    st.divider()
    execute_btn = st.button("ğŸš€ å¼€å§‹å¯è§†åŒ–", key="viz_execute_button", use_container_width=True)
    if execute_btn:
        if not uploaded_file or not save_filename:
            st.warning("âš ï¸ è¯·ç¡®ä¿å·²ä¸Šä¼ æ•°æ®æ–‡ä»¶å¹¶è¾“å…¥è¾“å‡ºæ–‡ä»¶å")
            return
        with st.spinner("ğŸ”„ æ­£åœ¨ç”Ÿæˆå¯è§†åŒ–æŠ¥è¡¨ï¼Œè¯·ç¨å€™..."):
            save_path = unique_tmp_path(save_filename)
            df = _read_excel_cached(uploaded_file, sheet_name="æºæ•°æ®")
            if df.empty:
                st.warning("ğŸ“‚ ä¸Šä¼ çš„æ–‡ä»¶ä¸ºç©ºæˆ–ä¸åŒ…å«'æºæ•°æ®'å·¥ä½œè¡¨ï¼Œè¯·æ£€æŸ¥æ•°æ®æ–‡ä»¶")
                return
            # Brand aggregation
            brand_words = []
            b_status = st.empty()
            b_prog = st.progress(0)
            b_status.text("æ­£åœ¨å¤„ç†å“ç‰Œè¯...")
            step = max(1, len(df) // 10)
            for idx, row in df.iterrows():
                vol = row["æœç´¢é‡"] if pd.notna(row["æœç´¢é‡"]) else 0
                brands = [b.strip() for b in str(row["å“ç‰Œ"]).split(",") if b.strip()]
                for b in brands:
                    brand_words.append({"å“ç‰Œåç§°": b, "æœç´¢é‡": vol})
                if (idx + 1) % step == 0 or idx == len(df) - 1:
                    b_prog.progress((idx + 1) / len(df))
            brand_df = pd.DataFrame()
            if brand_words:
                brand_df = pd.DataFrame(brand_words).groupby("å“ç‰Œåç§°", as_index=False)["æœç´¢é‡"].sum()
                brand_df = aggregate_top_n(brand_df, "æœç´¢é‡", "å“ç‰Œåç§°")
            b_status.text("å“ç‰Œè¯å¤„ç†å®Œæˆ")
            b_prog.empty()
            b_status.empty()
            # Param aggregation (single pass)
            excluded = {"æœç´¢è¯", "æœç´¢é‡", "å“ç‰Œåç§°", "å“ç‰Œ", "ç‰¹æ€§å‚æ•°", "è¯æ€§"}
            param_cols = [c for c in df.columns if c not in excluded]
            param_heats: Dict[str, List[Dict]] = {c: [] for c in param_cols}
            p_status = st.empty()
            p_prog = st.progress(0)
            p_status.text("æ­£åœ¨å¤„ç†å‚æ•°...")
            for idx, row in df.iterrows():
                vol = row["æœç´¢é‡"] if pd.notna(row["æœç´¢é‡"]) else 0
                for c in param_cols:
                    val = str(row[c]) if pd.notna(row[c]) else ""
                    for v in [v.strip() for v in val.split(",") if v.strip()]:
                        param_heats[c].append({"å‚æ•°å€¼": v, "æœç´¢é‡": vol})
                if (idx + 1) % step == 0 or idx == len(df) - 1:
                    p_prog.progress((idx + 1) / len(df))
            p_status.text("å‚æ•°å¤„ç†å®Œæˆ")
            p_prog.empty()
            p_status.empty()
            # Traffic structure
            traffic_df = df[["è¯æ€§", "æœç´¢é‡"]].groupby("è¯æ€§", as_index=False)["æœç´¢é‡"].sum()
            traffic_df = aggregate_top_n(traffic_df, "æœç´¢é‡", "è¯æ€§")
            # Workbook
            s_status = st.empty()
            s_prog = st.progress(0)
            s_status.text("æ­£åœ¨ç”ŸæˆExcelå·¥ä½œç°¿...")
            s_prog.progress(0.3)
            wb = Workbook()
            if "Sheet" in wb.sheetnames:
                wb.remove(wb["Sheet"])
            ws = wb.create_sheet("æºæ•°æ®")
            for r in dataframe_to_rows(df, index=False, header=True):
                ws.append(r)
            s_prog.progress(0.6)
            if not brand_df.empty:
                ws = wb.create_sheet("å“ç‰Œè¯æ‹†è§£")
                for r in dataframe_to_rows(brand_df, index=False, header=True):
                    ws.append(r)
            s_prog.progress(0.7)
            param_dfs: Dict[str, pd.DataFrame] = {}
            active_params = [c for c in param_cols if param_heats[c]]
            for i, c in enumerate(active_params):
                heats = param_heats[c]
                if heats:
                    pdf = pd.DataFrame(heats).groupby("å‚æ•°å€¼", as_index=False)["æœç´¢é‡"].sum()
                    pdf = aggregate_top_n(pdf, "æœç´¢é‡", "å‚æ•°å€¼")
                    param_dfs[c] = pdf
                    clean = re.sub(r"[\/*?[\]]", "", c)[:31]
                    ws = wb.create_sheet(f"{clean}æ‹†è§£")
                    for r in dataframe_to_rows(pdf, index=False, header=True):
                        ws.append(r)
                s_prog.progress(0.7 + 0.3 * (i + 1) / max(1, len(active_params)))
            if not traffic_df.empty:
                ws = wb.create_sheet("å“ç±»æµé‡ç»“æ„")
                for r in dataframe_to_rows(traffic_df, index=False, header=True):
                    ws.append(r)
            s_prog.progress(1.0)
            s_status.text("å·¥ä½œç°¿ç”Ÿæˆå®Œæˆ")
            s_status.empty()
            s_prog.empty()
            buffer = save_workbook_to_buffer(wb)
            st.success("âœ… æ•°æ®å¤„ç†å®Œæˆï¼Œæ­£åœ¨ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
            st.markdown("### ğŸ“Š æ•°æ®å¯è§†åŒ–")
            if not brand_df.empty:
                pie_chart(brand_df, "æœç´¢é‡", "å“ç‰Œåç§°", "å“ç‰Œè¯æ‹†è§£")
            for c in param_cols:
                if c in param_dfs:
                    pie_chart(param_dfs[c], "æœç´¢é‡", "å‚æ•°å€¼", f"{c} å‚æ•°æœç´¢é‡åˆ†å¸ƒ")
            if not traffic_df.empty:
                pie_chart(traffic_df, "æœç´¢é‡", "è¯æ€§", "æµé‡ç»“æ„")
            st.divider()
            ts = get_timestamp()
            out_name = f"viz_result_{ts}.xlsx"
            out_path = os.path.join("/tmp", out_name)
            save_func = lambda: wb.save(out_path)
            render_download_section(
                buffer,
                out_name,
                "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                "ğŸ“¥ ä¸‹è½½å®Œæ•´æŠ¥è¡¨",
                "viz",
                has_save=True,
                save_func=save_func,
                save_path=out_path,
            )

# æ•°æ®æ¸…ç†
def data_clean_app():
    render_app_header("ğŸ§¹ DC - æ•°æ®æ¸…ç†: åˆ é™¤ç¬¬ä¸€è¡Œ", "æ‰¹é‡åˆ é™¤Excel/CSVæ–‡ä»¶çš„ç¬¬ä¸€è¡Œæ•°æ®å¹¶é‡æ–°æ‰“åŒ…")
    col1, col2 = st.columns([2, 1])
    with col1:
        uploaded_file = st.file_uploader(
            "é€‰æ‹©ä¸€ä¸ª .zip æ–‡ä»¶(åŒ…å« XLSX æˆ– CSV æ–‡ä»¶)",
            type=["zip"],
            key="clean_files",
        )
    with col2:
        output_filename = st.text_input("è¾“å‡ºæ–‡ä»¶å", "cleaned_files.zip", key="clean_save")
    st.divider()
    execute_btn = st.button("ğŸš€ å¼€å§‹æ¸…ç†", key="clean_button", use_container_width=True)
    if execute_btn:
        if not uploaded_file or not output_filename:
            st.warning("âš ï¸ è¯·ç¡®ä¿å·²é€‰æ‹© .zip æ–‡ä»¶å¹¶è¾“å…¥è¾“å‡ºæ–‡ä»¶å")
            return
        with st.spinner("ğŸ”„ æ­£åœ¨æ¸…ç†æ–‡ä»¶ï¼Œè¯·ç¨å€™..."):
            def cb_clean(df, fname, tdir):
                df = df.iloc[1:].reset_index(drop=True)
                out_path = os.path.join(tdir, f"cleaned_{fname}")
                ext = os.path.splitext(fname)[1].lower()
                write_processed_file(df, out_path, ext)
                return out_path
            processed = process_zip_files(uploaded_file, read_file_clean, cb_clean)
            if not processed:
                return
            status = st.empty()
            prog = st.progress(0)
            status.text("æ­£åœ¨æ‰“åŒ…ZIPæ–‡ä»¶...")
            buffer = io.BytesIO()
            with zipfile.ZipFile(buffer, "w", zipfile.ZIP_DEFLATED, compresslevel=9) as nz:
                nz.setpassword(None)
                for i, p in enumerate(processed):
                    original_name = os.path.basename(p).replace("cleaned_", "")
                    nz.write(p, original_name, compress_type=zipfile.ZIP_DEFLATED)
                    prog.progress((i + 1) / len(processed))
            buffer.seek(0)
            status.text("æ‰“åŒ…å®Œæˆ")
            status.empty()
            prog.empty()
            st.success(f"âœ… æˆåŠŸæ¸…ç† {len(processed)} ä¸ªæ–‡ä»¶")
            render_download_section(
                buffer,
                output_filename,
                "application/zip",
                "ğŸ“¥ ä¸‹è½½æ¸…ç†åçš„ ZIP æ–‡ä»¶",
                "cleaned",
                has_save=False,
            )

# å‰‚å‹æ‰“æ ‡å·¥å…·ï¼ˆæ–°æ•´åˆçš„åŠŸèƒ½ï¼‰
class PackFormLabeler:
    def __init__(self):
        """åˆå§‹åŒ–å‰‚å‹åˆ†ç±»å’Œæ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼"""
        self.pack_forms = {
            'Capsule': [
                # è‹±æ–‡
                r'\bcapsule\b', r'\bcapsules\b', r'\bcap\b', r'\bcaps\b',
                r'\bgelcap\b', r'\bgelcaps\b', 
                # ä¸­æ–‡
                r'\bèƒ¶å›Š\b', r'\bè½¯èƒ¶å›Š\b', r'\bç¡¬èƒ¶å›Š\b', r'\bè‚ æº¶èƒ¶å›Š\b',
                r'\bç¼“é‡Šèƒ¶å›Š\b', r'\bæ§é‡Šèƒ¶å›Š\b'
            ],
            'Tablet': [
                # è‹±æ–‡
                r'\btablet\b',r'\bcaplet\b', r'\btablets\b', r'\btab\b', r'\btabs\b',
                r'\bchewable\b',    r'\bchewables\b', r'\bsublingual\b', r'\benteric\b', r'\bCaplets\b', 
                # ä¸­æ–‡
                r'\bç‰‡å‰‚\b', r'\bç‰‡\b', r'\bå’€åš¼ç‰‡\b', r'\bå«ç‰‡\b',
                r'\bèˆŒä¸‹ç‰‡\b', r'\bè‚ æº¶ç‰‡\b', r'\bç¼“é‡Šç‰‡\b', r'\bæ§é‡Šç‰‡\b'
            ],
            'Powder': [
                # è‹±æ–‡
                r'\bpowder\b', r'\bpowders\b', r'\bpwd\b', r'\bgranule\b',
                r'\bgranules\b', r'\bdrink\b', r'\bdrinks\b',r'\bCrystal\b',
                # ä¸­æ–‡
                r'\bç²‰å‰‚\b', r'\bç²‰æœ«\b', r'\bå†²å‰‚\b', r'\bæ•£å‰‚\b',
                r'\bé¢—ç²’å‰‚\b', r'\bå†²é¥®\b', r'\bé¥®å“\b'
            ],
            'Gummy': [
                # è‹±æ–‡
                r'\bgummy\b', r'\bgummies\b',r'\bGummy\b', r'\bGummies\b',
                r'\bcandy\b', r'\bcandies\b', r'\bjelly\b', r'\bjellies\b',
                # ä¸­æ–‡
                r'è½¯ç³–', r'å’€åš¼ç³–', r'æœå†»', r'ç³–æœ',
                r'å£é¦™ç³–', r'å’€åš¼ç‰‡'
            ],
            'Drop': [
                # è‹±æ–‡
                r'\bdrop\b', r'\bdrops\b', r'\btincture\b', r'\btinctures\b',
                r'\bessence\b', r'\bessences\b', r'\bFL OZs\b',
                r'\bliquid\s*drop\b', r'\bliquid\s*drops\b',
                # ä¸­æ–‡
                r'æ»´å‰‚', r'æ»´æ¶²', r'é…Šå‰‚', r'ç²¾å',
                r'ç²¾åæ¶²', r'æ¶²ä½“æ»´å‰‚', r'æ¶²ä½“æ»´æ¶²'
            ],
            'Softgel': [
                # è‹±æ–‡
                r'\bsoftgel\b', r'\bsoftgels\b', r'\bsoft\s*gel\b',
                r'\bgel\b', r'\bgels\b', r'\bgelatin\b',
                # ä¸­æ–‡
                r'è½¯èƒ¶å›Š', r'è½¯èƒ¶', r'æ˜èƒ¶'
            ],
            'Liquid': [
                # è‹±æ–‡
                r'\bliquid\b', r'\bliquids\b', r'\bsyrup\b', r'\bsyrups\b',
                r'\bsuspension\b', r'\bsuspensions\b', r'\belixir\b',
                r'\bsolution\b', r'\bsolutions\b', r'\bemulsion\b',
                # ä¸­æ–‡
                r'æ¶²ä½“', r'å£æœæ¶²', r'ç³–æµ†', r'æ··æ‚¬æ¶²',
                r'æº¶æ¶²', r'ä¹³å‰‚', r'æ°´å‰‚'
            ],
            'Cream': [
                # è‹±æ–‡
                r'\bcream\b', r'\bcreams\b', r'\bointment\b', r'\bointments\b',
                # ä¸­æ–‡
                r'ä¹³è†', r'éœœå‰‚', r'è½¯è†', r'è†å‰‚'
            ],
            'Spray': [
                # è‹±æ–‡
                r'\bspray\b', r'\bsprays\b', r'\binhaler\b', r'\binhalers\b',
                # ä¸­æ–‡
                r'å–·é›¾', r'å–·å‰‚', r'å¸å…¥å™¨', r'å¸å…¥å‰‚'
            ],
            'Lotion': [
                # è‹±æ–‡
                r'\blotion\b', r'\blotions\b',
                # ä¸­æ–‡
                r'ä¹³æ¶²', r'æ´—å‰‚'
            ],
            'Patch': [
                # è‹±æ–‡
                r'\bpatch\b', r'\bpatches\b',
                # ä¸­æ–‡
                r'è´´å‰‚', r'è´´ç‰‡', r'è´´è†'
            ],
            'Suppository': [
                # è‹±æ–‡
                r'\bsuppository\b', r'\bsuppositories\b',
                # ä¸­æ–‡
                r'æ “å‰‚', r'åè¯'
            ],
            'Oil': [
                # è‹±æ–‡
                r'\boil\b', r'\boils\b', r'\boils\b',
                r'\bessential\s*oil\b', r'\bessential\s*oils\b',
                r'\bfish\s*oil\b', r'\bomega\s*oil\b',
                r'\bcarrier\s*oil\b', r'\bcarrier\s*oils\b',
                # ä¸­æ–‡
                r'æ²¹', r'ç²¾æ²¹', r'é±¼æ²¹', r'æ¤ç‰©æ²¹', r'æ©„æ¦„æ²¹',
                r'æ¤°å­æ²¹', r'äºšéº»ç±½æ²¹', r'æœˆè§è‰æ²¹'
            ]
        }
        
        # æ ‡å‡†åŒ–æ˜ å°„è¡¨ 
        self.standardization_map = {
    # ========================================
    # Capsule ç›¸å…³
    # ========================================
    'capsule': 'Capsule', 'capsules': 'Capsule',
    'cap': 'Capsule', 'caps': 'Capsule', 'capsu': 'Capsule',
    'gelcaps': 'Capsule', 'gelcap': 'Capsule',
    # é¦–å­—æ¯å¤§å†™
    'Capsule': 'Capsule', 'Capsules': 'Capsule','VegCap': 'Capsule',
    'Cap': 'Capsule', 'Caps': 'Capsule', 'Capsu': 'Capsule',
    'Gelcaps': 'Capsule', 'Gelcap': 'Capsule',
    # å…¨å¤§å†™
    'CAPSULE': 'Capsule', 'CAPSULES': 'Capsule',
    'CAP': 'Capsule', 'CAPS': 'Capsule', 'CAPSU': 'Capsule',
    'GELCAPS': 'Capsule', 'GELCAP': 'Capsule',

    # ========================================
    # Tablet ç›¸å…³ï¼ˆåŒ…å« capletï¼‰
    # ========================================
    'tablet': 'Tablet', 'tablets': 'Tablet',
    'tab': 'Tablet', 'tabs': 'Tablet',
    'caplet': 'Tablet', 'caplets': 'Tablet',  # âœ… æ­£ç¡®å½’ç±»åˆ° Tablet
    'chewable': 'Tablet', 'chewables': 'Tablet',
    'chew': 'Tablet', 'chews': 'Tablet',
    'sublingual': 'Tablet', 'enteric': 'Tablet',
    # é¦–å­—æ¯å¤§å†™
    'Tablet': 'Tablet', 'Tablets': 'Tablet',
    'Tab': 'Tablet', 'Tabs': 'Tablet',
    'Caplet': 'Tablet', 'Caplets': 'Tablet',  # âœ… é¦–å­—æ¯å¤§å†™ä¹Ÿå½’ä¸º Tablet
    'Chewable': 'Tablet', 'Chewables': 'Tablet',
    'Chew': 'Tablet', 'Chews': 'Tablet',
    'Sublingual': 'Tablet', 'Enteric': 'Tablet',
    # å…¨å¤§å†™
    'TABLET': 'Tablet', 'TABLETS': 'Tablet',
    'TAB': 'Tablet', 'TABS': 'Tablet',
    'CAPLET': 'Tablet', 'CAPLETS': 'Tablet',  # âœ… å…¨å¤§å†™ä¹Ÿæ­£ç¡®æ˜ å°„
    'CHEWABLE': 'Tablet', 'CHEWABLES': 'Tablet',
    'CHEW': 'Tablet', 'CHEWS': 'Tablet',
    'SUBLINGUAL': 'Tablet', 'ENTERIC': 'Tablet',

    # ========================================
    # Powder ç›¸å…³
    # ========================================
    'powder': 'Powder', 'powders': 'Powder','Powdered': 'Powder',
    'granule': 'Powder', 'granules': 'Powder',
    'Crystals': 'Powder','Crystal': 'Powder','crystal': 'Powder','crystals': 'Powder',
    'pwd': 'Powder',
    'Powder': 'Powder', 'Powders': 'Powder',
    'Granule': 'Powder', 'Granules': 'Powder',
    'Pwd': 'Powder',
    'POWDER': 'Powder', 'POWDERS': 'Powder',
    'GRANULE': 'Powder', 'GRANULES': 'Powder',
    'PWD': 'Powder',

    # ========================================
    # Gummy ç›¸å…³
    # ========================================
    'gummy': 'Gummy', 'gummies': 'Gummy',
    'jelly': 'Gummy', 'jellies': 'Gummy',
    'gumm': 'Gummy',
    'Gummy': 'Gummy', 'Gummies': 'Gummy',
    'Jelly': 'Gummy', 'Jellies': 'Gummy',
    'Gumm': 'Gummy',
    'GUMMY': 'Gummy', 'GUMMIES': 'Gummy',
    'JELLY': 'Gummy', 'JELLIES': 'Gummy',
    'GUMM': 'Gummy',

    # ========================================
    # Drop ç›¸å…³
    # ========================================
    'drop': 'Drop', 'drops': 'Drop',
    'tincture': 'Drop', 'tinctures': 'Drop',
    'fl oz': 'Drop', 'fl. oz.': 'Drop',
    'Drop': 'Drop', 'Drops': 'Drop',
    'Tincture': 'Drop', 'Tinctures': 'Drop',
    'Fl Oz': 'Drop', 'Fl. Oz.': 'Drop',
    'DROP': 'Drop', 'DROPS': 'Drop',
    'TINCTURE': 'Drop', 'TINCTURES': 'Drop',
    'FL OZ': 'Drop', 'FL. OZ.': 'Drop',

    # ========================================
    # Softgel ç›¸å…³
    # ========================================
    'softgel': 'Softgel', 'softgels': 'Softgel','sof': 'Softgel',
    'gel': 'Softgel', 'gels': 'Softgel',
    'Softgel': 'Softgel', 'Softgels': 'Softgel',
    'Gel': 'Softgel', 'Gels': 'Softgel',
    'SOFTGEL': 'Softgel', 'SOFTGELS': 'Softgel',
    'GEL': 'Softgel', 'GELS': 'Softgel',

    # ========================================
    # Liquid ç›¸å…³
    # ========================================
    'liquid': 'Liquid', 'liquids': 'Liquid',
    'syrup': 'Liquid', 'syrups': 'Liquid',
    'solution': 'Liquid', 'solutions': 'Liquid',
    'suspension': 'Liquid', 'suspensions': 'Liquid',
    'Liquid': 'Liquid', 'Liquids': 'Liquid',
    'Syrup': 'Liquid', 'Syrups': 'Liquid',
    'Solution': 'Liquid', 'Solutions': 'Liquid',
    'Suspension': 'Liquid', 'Suspensions': 'Liquid',
    'LIQUID': 'Liquid', 'LIQUIDS': 'Liquid',
    'SYRUP': 'Liquid', 'SYRUPS': 'Liquid',
    'SOLUTION': 'Liquid', 'SOLUTIONS': 'Liquid',
    'SUSPENSION': 'Liquid', 'SUSPENSIONS': 'Liquid',

    # ========================================
    # Cream ç›¸å…³
    # ========================================
    'cream': 'Cream', 'creams': 'Cream',
    'ointment': 'Cream', 'ointments': 'Cream',
    'Cream': 'Cream', 'Creams': 'Cream',
    'Ointment': 'Cream', 'Ointments': 'Cream',
    'CREAM': 'Cream', 'CREAMS': 'Cream',
    'OINTMENT': 'Cream', 'OINTMENTS': 'Cream',

    # ========================================
    # Spray ç›¸å…³
    # ========================================
    'spray': 'Spray', 'sprays': 'Spray',
    'inhaler': 'Spray', 'inhalers': 'Spray',
    'Spray': 'Spray', 'Sprays': 'Spray',
    'Inhaler': 'Spray', 'Inhalers': 'Spray',
    'SPRAY': 'Spray', 'SPRAYS': 'Spray',
    'INHALER': 'Spray', 'INHALERS': 'Spray',

    # ========================================
    # Lotion ç›¸å…³
    # ========================================
    'lotion': 'Lotion', 'lotions': 'Lotion',
    'Lotion': 'Lotion', 'Lotions': 'Lotion',
    'LOTION': 'Lotion', 'LOTIONS': 'Lotion',

    # ========================================
    # Patch ç›¸å…³
    # ========================================
    'patch': 'Patch', 'patches': 'Patch',
    'Patch': 'Patch', 'Patches': 'Patch',
    'PATCH': 'Patch', 'PATCHES': 'Patch',

    # ========================================
    # Suppository ç›¸å…³
    # ========================================
    'suppository': 'Suppository', 'suppositories': 'Suppository',
    'Suppository': 'Suppository', 'Suppositories': 'Suppository',
    'SUPPOSITORY': 'Suppository', 'SUPPOSITORIES': 'Suppository',

    # ========================================
    # Oil ç›¸å…³
    # ========================================
    'oil': 'Oil', 'oils': 'Oil',
    'essential oil': 'Oil', 'essential oils': 'Oil',
    'fish oil': 'Oil', 'omega oil': 'Oil',
    'carrier oil': 'Oil', 'carrier oils': 'Oil',
    'Oil': 'Oil', 'Oils': 'Oil',
    'Carrier Oil': 'Oil', 'Carrier Oils': 'Oil',
    'OIL': 'Oil', 'OILS': 'Oil',
    'CARRIER OIL': 'Oil', 'CARRIER OILS': 'Oil',

    # ========================================
    # Others ç›¸å…³
    # ========================================
    'bag': 'Others', 'bags': 'Others','Tea bags': 'Others',
    'teabag': 'Others', 'teabags': 'Others',
    'strip': 'Others', 'strips': 'Others',
    'stick': 'Others', 'sticks': 'Others',
    'other': 'Others', 'others': 'Others',
    'strippy': 'Others',
    # é¦–å­—æ¯å¤§å†™
    'Bag': 'Others', 'Bags': 'Others',
    'Teabag': 'Others', 'Teabags': 'Others',
    'Strip': 'Others', 'Strips': 'Others',
    'Stick': 'Others', 'Sticks': 'Others',
    'Other': 'Others', 'Others': 'Others',
    'Strippy': 'Others',
    # å…¨å¤§å†™
    'BAG': 'Others', 'BAGS': 'Others',
    'TEABAG': 'Others', 'TEABAGS': 'Others',
    'STRIP': 'Others', 'STRIPS': 'Others',
    'STICK': 'Others', 'STICKS': 'Others',
    'OTHER': 'Others', 'OTHERS': 'Others',
    'STRIPPY': 'Others',
    }
    
    def detect_others_forms(self, product_text):
        """
        æ£€æµ‹Othersç±»å‰‚å‹
        
        Args:
            product_text (str): äº§å“æè¿°æ–‡æœ¬
            
        Returns:
            list: æ£€æµ‹åˆ°çš„Othersç±»å‰‚å‹åˆ—è¡¨
        """
        if pd.isna(product_text) or not isinstance(product_text, str):
            return []
        
        others_patterns = {
            'Injection': [r'\binjection\b', r'\binjections\b', r'æ³¨å°„å‰‚', r'é’ˆå‰‚'],
            'Nasal': [r'\bnasal\b', r'é¼»ç”¨', r'é¼»è…”'],
            'Topical': [r'\btopical\b', r'å¤–ç”¨', r'å±€éƒ¨'],
            'External': [r'\bexternal\b', r'å¤–ç”¨', r'å¤–éƒ¨'],
            'Bag': [r'\bbag\b', r'\bbags\b', r'è¢‹è£…', r'åŒ…è£…'],
            'Teabag': [r'\bteabag\b', r'\bteabags\b', r'èŒ¶åŒ…', r'è¢‹æ³¡èŒ¶'],
            'Strip': [r'\bstrip\b', r'\bstrips\b', r'æ¡è£…', r'æ¡å‰‚'],
            'Stick': [r'\bstick\b', r'\bsticks\b', r'æ£’çŠ¶', r'æ£’å‰‚']
        }
        
        detected_others = []
        text_lower = product_text.lower()
        
        for form, patterns in others_patterns.items():
            for pattern in patterns:
                if re.search(pattern, text_lower, re.IGNORECASE):
                    detected_others.append(form)
                    break
        
        return detected_others

    def standardize_pack_form(self, pack_form):
        """
        æ ‡å‡†åŒ–å‰‚å‹åç§°
        
        Args:
            pack_form (str): åŸå§‹å‰‚å‹åç§°
            
        Returns:
            str: æ ‡å‡†åŒ–åçš„å‰‚å‹åç§°
        """
        if pd.isna(pack_form) or pack_form == '':
            return pack_form
        
        # è½¬æ¢ä¸ºå­—ç¬¦ä¸²
        pack_form_str = str(pack_form).strip()
        
        # æ£€æŸ¥æ˜¯å¦å·²ç»åœ¨æ ‡å‡†æ˜ å°„è¡¨ä¸­
        if pack_form_str in self.standardization_map:
            return self.standardization_map[pack_form_str]
        
        # æ£€æŸ¥æ˜¯å¦åŒ¹é…æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼
        for standard_form, patterns in self.pack_forms.items():
            for pattern in patterns:
                if re.search(pattern, pack_form_str, re.IGNORECASE):
                    return standard_form
        
        # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°ï¼Œè¿”å›åŸå€¼
        return pack_form_str
    
    def detect_pack_form(self, product_text):
        """
        ä»äº§å“æè¿°ä¸­æ£€æµ‹å‰‚å‹
        
        Args:
            product_text (str): äº§å“æè¿°æ–‡æœ¬
            
        Returns:
            tuple: (æ£€æµ‹åˆ°çš„å‰‚å‹åˆ—è¡¨, åŒ¹é…çš„æ–‡æœ¬åˆ—è¡¨)
        """
        if pd.isna(product_text) or not isinstance(product_text, str):
            return [], []
        
        detected_forms = []
        matched_texts = []
        
        # è½¬æ¢ä¸ºå°å†™è¿›è¡ŒåŒ¹é…
        text_lower = product_text.lower()
        
        # æ£€æŸ¥ä¸»è¦å‰‚å‹
        for form, patterns in self.pack_forms.items():
            for pattern in patterns:
                matches = re.findall(pattern, text_lower)
                if matches:
                    detected_forms.append(form)
                    matched_texts.extend(matches)
        
        # æ£€æŸ¥Othersç±»å‰‚å‹
        others_forms = self.detect_others_forms(product_text)
        if others_forms:
            detected_forms.append('Others')
            matched_texts.extend(others_forms)
        
        return detected_forms, matched_texts
    
    def classify_pack_form(self, detected_forms):
        """
        æ ¹æ®æ£€æµ‹åˆ°çš„å‰‚å‹è¿›è¡Œåˆ†ç±»
        
        Args:
            detected_forms (list): æ£€æµ‹åˆ°çš„å‰‚å‹åˆ—è¡¨
            
        Returns:
            str: åˆ†ç±»ç»“æœ
        """
        if not detected_forms:
            return 'Others'
        
        # å»é‡
        unique_forms = list(set(detected_forms))
        
        # ç‰¹æ®Šå¤„ç†ï¼šå¦‚æœåŒæ—¶æ£€æµ‹åˆ°Liquidå’ŒDropï¼Œä¼˜å…ˆå½’ç±»ä¸ºDrop
        if 'Liquid' in unique_forms and 'Drop' in unique_forms:
            return 'Drop'
        
        if len(unique_forms) == 1:
            return unique_forms[0]
        elif len(unique_forms) > 1:
            return 'Bundle'
        else:
            return 'Others'
    
    def process_dataframe(self, df):
        """
        å¤„ç†DataFrameï¼Œå¯¹Pack formåˆ—è¿›è¡Œæ™ºèƒ½æ‰“æ ‡å’Œæ ‡å‡†åŒ–
        
        Args:
            df (pd.DataFrame): åŒ…å«'Pack form'å’Œ'Product'åˆ—çš„DataFrame
            
        Returns:
            pd.DataFrame: å¤„ç†åçš„DataFrame
        """
        # å¤åˆ¶DataFrameé¿å…ä¿®æ”¹åŸå§‹æ•°æ®
        df_processed = df.copy()
        
        # æ·»åŠ æ–°åˆ—
        df_processed['Matched_Pack_Form'] = ''
        df_processed['Match_Source'] = ''
        df_processed['Is_Originally_Empty'] = df_processed['Pack form'].isna()
        df_processed['Confidence_Score'] = 0.0
        df_processed['Standardization_Applied'] = False
        
        # ç¬¬ä¸€æ­¥ï¼šæ ‡å‡†åŒ–å·²å­˜åœ¨çš„å‰‚å‹
        standardization_count = 0
        for idx, row in df_processed.iterrows():
            if pd.notna(row['Pack form']) and row['Pack form'] != '':
                original_form = row['Pack form']
                standardized_form = self.standardize_pack_form(original_form)
                
                if standardized_form != original_form:
                    df_processed.at[idx, 'Pack form'] = standardized_form
                    df_processed.at[idx, 'Standardization_Applied'] = True
                    standardization_count += 1
        
        # ç¬¬äºŒæ­¥ï¼šå¤„ç†ç©ºçš„Pack formåˆ—
        processed_count = 0
        for idx, row in df_processed.iterrows():
            # åªå¤„ç†Pack formä¸ºç©ºçš„è¡Œ
            if pd.isna(row['Pack form']) or row['Pack form'] == '':
                product_text = row['Product']
                detected_forms, matched_texts = self.detect_pack_form(product_text)
                
                if detected_forms:
                    classified_form = self.classify_pack_form(detected_forms)
                    
                    # å®é™…å¡«å……åˆ°Pack formåˆ—
                    df_processed.at[idx, 'Pack form'] = classified_form
                    
                    # åŒæ—¶ä¿å­˜åˆ°æ–°åˆ—
                    df_processed.at[idx, 'Matched_Pack_Form'] = classified_form
                    df_processed.at[idx, 'Match_Source'] = ', '.join(matched_texts)
                    
                    # è®¡ç®—ç½®ä¿¡åº¦åˆ†æ•°
                    confidence = min(len(detected_forms) / 2.0, 1.0)
                    df_processed.at[idx, 'Confidence_Score'] = confidence
                    
                    processed_count += 1
        
        return df_processed, processed_count, standardization_count
    
    def generate_standardization_report(self, df_processed):
        """
        ç”Ÿæˆæ ‡å‡†åŒ–å¤„ç†æŠ¥å‘Š
        
        Args:
            df_processed (pd.DataFrame): å¤„ç†åçš„DataFrame
            
        Returns:
            dict: æ ‡å‡†åŒ–æŠ¥å‘Š
        """
        report = {
            'total_rows': len(df_processed),
            'standardization_applied': df_processed['Standardization_Applied'].sum(),
            'originally_empty': df_processed['Is_Originally_Empty'].sum(),
            'successfully_filled': 0,
            'final_empty': 0,
            'pack_form_distribution': {},
            'standardization_examples': []
        }
        
        # è®¡ç®—å¡«å……ç»Ÿè®¡
        report['successfully_filled'] = report['originally_empty'] - df_processed['Pack form'].isna().sum()
        report['final_empty'] = df_processed['Pack form'].isna().sum()
        
        # å‰‚å‹åˆ†å¸ƒ
        pack_form_counts = df_processed['Pack form'].value_counts()
        report['pack_form_distribution'] = pack_form_counts.to_dict()
        
        # æ ‡å‡†åŒ–ç¤ºä¾‹
        standardized_rows = df_processed[df_processed['Standardization_Applied'] == True]
        if len(standardized_rows) > 0:
            for idx, row in standardized_rows.head(10).iterrows():
                report['standardization_examples'].append({
                    'row': idx + 1,
                    'product': str(row['Product'])[:80] + "..." if len(str(row['Product'])) > 80 else str(row['Product']),
                    'pack_form': row['Pack form']
                })
        
        return report

def pack_form_labeler_app():
    render_app_header("ğŸ·ï¸ å‰‚å‹æ‰“æ ‡å·¥å…·", "é€šè¿‡åŒ¹é…äº§å“æ ‡é¢˜ï¼Œè‡ªåŠ¨è¯†åˆ«å‰‚å‹å¹¶å¡«å……åˆ°ç©ºçš„Pack formåˆ—ä¸­")
    col1, col2 = st.columns([2, 1])
    with col1:
        uploaded_file = st.file_uploader(
            "é€‰æ‹©æ‚¨çš„Excelæ–‡ä»¶ (.xlsxæ ¼å¼)",
            type=["xlsx"],
            key="pack_form_file"
        )
    with col2:
        save_filename = st.text_input("è¾“å‡ºæ–‡ä»¶å", "labeled_pack_forms.xlsx", key="pack_form_save")
    st.divider()
    if uploaded_file is not None:
        try:
            df_input = _read_excel_cached(uploaded_file)
            st.markdown("#### æ–‡ä»¶ä¿¡æ¯")
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("æ€»è¡Œæ•°", len(df_input))
            with col2:
                st.metric("æ€»åˆ—æ•°", len(df_input.columns))
            with col3:
                empty_count = df_input['Pack form'].isna().sum() if 'Pack form' in df_input.columns else 0
                st.metric("Pack formç©ºå€¼", empty_count)
            required_columns = ['Pack form', 'Product']
            missing_columns = [col for col in required_columns if col not in df_input.columns]
            if missing_columns:
                st.error(f"æ–‡ä»¶ç¼ºå°‘å¿…è¦çš„åˆ—: {missing_columns}")
            else:
                st.success("æ–‡ä»¶æ ¼å¼æ­£ç¡®ï¼ŒåŒ…å«æ‰€æœ‰å¿…è¦çš„åˆ—")
                st.markdown("#### æ•°æ®é¢„è§ˆ (å‰5è¡Œ)")
                st.dataframe(df_input.head(), use_container_width=True)
                st.divider()
                execute_btn = st.button("ğŸš€ å¼€å§‹å‰‚å‹æ‰“æ ‡", key="pack_form_button", use_container_width=True)
                if execute_btn:
                    with st.spinner("ğŸ”„ æ­£åœ¨è¿›è¡Œå‰‚å‹æ™ºèƒ½æ‰“æ ‡ï¼Œè¯·ç¨å€™..."):
                        try:
                            labeler = PackFormLabeler()
                            df_processed, processed_count, standardization_count = labeler.process_dataframe(df_input)
                            st.success("å‰‚å‹æ‰“æ ‡å®Œæˆï¼")
                            original_empty_count = (df_input['Pack form'].isna() | (df_input['Pack form'] == '')).sum()
                            final_empty_count = (df_processed['Pack form'].isna() | (df_processed['Pack form'] == '')).sum()
                            successfully_filled_count = original_empty_count - final_empty_count
                            col1, col2, col3, col4, col5 = st.columns(5)
                            with col1:
                                st.metric("åŸå§‹ç©ºå€¼", original_empty_count)
                            with col2:
                                st.metric("æˆåŠŸå¡«å……", successfully_filled_count)
                            with col3:
                                st.metric("æ ‡å‡†åŒ–å¤„ç†", standardization_count)
                            with col4:
                                st.metric("å¤„ç†åç©ºå€¼", final_empty_count)
                            with col5:
                                if original_empty_count > 0:
                                    success_rate = successfully_filled_count / original_empty_count * 100
                                    st.metric("æˆåŠŸç‡", f"{success_rate:.1f}%")
                                else:
                                    st.metric("æˆåŠŸç‡", "N/A")
                            if standardization_count > 0:
                                st.markdown("#### æ ‡å‡†åŒ–å¤„ç†è¯¦æƒ…")
                                st.info(f"å¯¹ {standardization_count} è¡Œå·²æœ‰å‰‚å‹è¿›è¡Œäº†æ ‡å‡†åŒ–å¤„ç†")
                            st.markdown("#### å‰‚å‹åˆ†å¸ƒ")
                            pack_form_counts = df_processed['Pack form'].value_counts()
                            st.bar_chart(pack_form_counts)
                            st.markdown("#### å¤„ç†ç»“æœé¢„è§ˆ (å‰5è¡Œ)")
                            st.dataframe(df_processed.head(), use_container_width=True)
                            buffer = save_df_to_buffer(df_processed)
                            ts = get_timestamp()
                            out_name = f"labeled_{ts}.xlsx"
                            out_path = os.path.join("/tmp", out_name)
                            save_func = lambda: df_processed.to_excel(out_path, index=False, engine="openpyxl")
                            render_download_section(
                                buffer,
                                out_name,
                                "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                                "ğŸ“¥ ä¸‹è½½æ‰“æ ‡åçš„Excelæ–‡ä»¶",
                                "pack_form",
                                has_save=True,
                                save_func=save_func,
                                save_path=out_path,
                            )
                            st.info("ä¸‹è½½çš„æ–‡ä»¶åŒ…å«ï¼šåŸå§‹æ•°æ®ã€å¡«å……å’Œæ ‡å‡†åŒ–åçš„Pack formåˆ—ï¼Œä»¥åŠæ–°å¢çš„åŒ¹é…ä¿¡æ¯åˆ—")
                        except Exception as e:
                            st.error(f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        except Exception as e:
            st.error(f"è¯»å–æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")

# ä¸»åº”ç”¨ç¨‹åº
def main():
    st.set_page_config(page_title=APP_CONFIG["app_title"], layout="wide", page_icon="ğŸ“Š", initial_sidebar_state="collapsed")
    st.markdown("""
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap');
        html, body, [class*="css"] {font-family: 'Inter', 'Segoe UI', sans-serif;}
        .main {background: linear-gradient(135deg, #f5f7fa 0%, #e9ecef 100%);}
        h1, h2, h3, h4, h5, h6 {color: #ffffff !important; font-weight: 600 !important;}
        .stButton > button {
            background: linear-gradient(135deg, #00a6e4 0%, #0088c2 100%);
            color: white; border: none; border-radius: 8px; padding: 0.6rem 1.5rem;
            font-weight: 600; font-size: 15px; transition: all 0.3s ease;
            box-shadow: 0 4px 6px rgba(0, 166, 228, 0.2);
        }
        .stButton > button:hover {
            background: linear-gradient(135deg, #0088c2 0%, #006a99 100%);
            box-shadow: 0 6px 12px rgba(0, 166, 228, 0.3); transform: translateY(-2px);
        }
        .stDownloadButton > button {background: linear-gradient(135deg, #00a6e4 0%, #0088c2 100%);
            color: white; border: none; border-radius: 8px; padding: 0.6rem 1.5rem;
            font-weight: 600; font-size: 15px; transition: all 0.3s ease;
            box-shadow: 0 4px 6px rgba(0, 166, 228, 0.2);
        }
        .stDownloadButton > button:hover {
            background: linear-gradient(135deg, #0088c2 0%, #006a99 100%);
            box-shadow: 0 6px 12px rgba(0, 166, 228, 0.3); transform: translateY(-2px);
        }
        .stFileUploader {background: white; border-radius: 10px; padding: 1.5rem; box-shadow: 0 2px 8px rgba(0,0,0,0.08);}
        [data-testid="stFileUploadDropzone"] {border: 2px dashed #00a6e4; border-radius: 8px; background: #f8fcff;}
        .stTextInput > div > div > input, .stTextArea > div > div > textarea {
            border: 2px solid #e0e0e0; border-radius: 8px; padding: 0.6rem; transition: all 0.3s ease; font-size: 14px;
        }
        .stTextInput > div > div > input:focus, .stTextArea > div > div > textarea:focus {
            border-color: #00a6e4; box-shadow: 0 0 0 3px rgba(0, 166, 228, 0.1);
        }
        .stProgress > div > div > div > div {background: linear-gradient(90deg, #00a6e4 0%, #0088c2 100%);}
        .stSuccess {background: linear-gradient(135deg, #d4edda 0%, #c3e6cb 100%); border-left: 4px solid #28a745; border-radius: 8px; padding: 1rem;}
        .stError {background: linear-gradient(135deg, #f8d7da 0%, #f5c6cb 100%); border-left: 4px solid #dc3545; border-radius: 8px; padding: 1rem;}
        .stWarning {background: linear-gradient(135deg, #fff3cd 0%, #ffeaa7 100%); border-left: 4px solid #ffc107; border-radius: 8px; padding: 1rem;}
        .stInfo {background: linear-gradient(135deg, #d1ecf1 0%, #bee5eb 100%); border-left: 4px solid #00a6e4; border-radius: 8px; padding: 1rem;}
        div[data-testid="column"] {background: white; padding: 1rem; border-radius: 10px; box-shadow: 0 2px 8px rgba(0,0,0,0.05);}
        .js-plotly-plot {border-radius: 10px; box-shadow: 0 4px 12px rgba(0,0,0,0.1);}
    </style>
    """, unsafe_allow_html=True)
    st.markdown(f"""
    <div style="background: linear-gradient(135deg, #00a6e4 0%, #0088c2 100%); padding: 2.5rem 2rem; border-radius: 15px; margin-bottom: 2rem; box-shadow: 0 8px 16px rgba(0,0,0,0.15);">
        <h1 style="color: white; margin: 0; font-size: 2.5rem; font-weight: 700;">ğŸ“Š å¸‚åœºæ´å¯Ÿå°ç¨‹åº</h1>
        <div style="display: flex; gap: 2rem; margin-top: 1rem; flex-wrap: wrap;">
            <span style="color: rgba(255,255,255,0.95); font-size: 14px;"><strong>ç‰ˆæœ¬:</strong> {APP_CONFIG["version"]}</span>
            <span style="color: rgba(255,255,255,0.95); font-size: 14px;"><strong>ä½œè€…:</strong> {APP_CONFIG["author"]}</span>
            <span style="color: rgba(255,255,255,0.95); font-size: 14px;"><strong>å…¬å¸:</strong> {APP_CONFIG["company"]}</span>
            <span style="color: rgba(255,255,255,0.95); font-size: 14px;"><strong>è”ç³»:</strong> {APP_CONFIG["contact"]}</span>
        </div>
    </div>
    """, unsafe_allow_html=True)
    st.markdown("""
    <div style="background: white; padding: 1.5rem; border-radius: 10px; margin-bottom: 2rem; box-shadow: 0 2px 8px rgba(0,0,0,0.08);">
        <h3 style="margin-top: 0; color: #333;">ğŸ¯ åŠŸèƒ½å¯¼èˆª</h3>
        <p style="color: #666; margin-bottom: 0;">é€‰æ‹©ä¸‹æ–¹åŠŸèƒ½æ¨¡å—å¼€å§‹æ‚¨çš„æ•°æ®åˆ†æä¹‹æ—…</p>
    </div>
    """, unsafe_allow_html=True)
    tabs = st.tabs(["ğŸ“Š åˆå¹¶æ•°æ®è¡¨æ ¼", "ğŸ” æœç´¢æµé‡æ´å¯Ÿ", "ğŸ“ˆ æµé‡å¯è§†åŒ–åˆ†æ", "ğŸ§¹ æ•°æ®æ¸…ç†å·¥å…·", "ğŸ·ï¸ å‰‚å‹æ‰“æ ‡å·¥å…·"])
    with tabs[0]:
        merge_data_app()
    with tabs[1]:
        search_insight_app()
    with tabs[2]:
        search_insight_viz_app()
    with tabs[3]:
        data_clean_app()
    with tabs[4]:
        pack_form_labeler_app()
    st.divider()
    st.markdown("""
    <div style="text-align: center; color: #666; padding: 2rem 0;">
        <p style="margin: 0;">Â© Anker Oceanwing Inc. | æµ·ç¿¼IDCå›¢é˜Ÿ</p>
        <p style="margin: 0.5rem 0 0 0; font-size: 13px;">å¸‚åœºæ´å¯Ÿå°ç¨‹åº v1.2.0 - è®©æ•°æ®åˆ†ææ›´ç®€å•</p>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()
