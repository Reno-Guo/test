import streamlit as st
import pandas as pd
import os
import re
from datetime import datetime
import io
import zipfile
import tempfile
from openpyxl import Workbook
from openpyxl.utils.dataframe import dataframe_to_rows
import plotly.express as px
from uuid import uuid4
from typing import Callable, List, Any, Dict

# === Concurrency-safe session + helpers ===
if "SID" not in st.session_state:
    st.session_state.SID = uuid4().hex[:6]

def unique_tmp_path(suggest_name: str, default_ext: str = ".xlsx") -> str:
    base, ext = os.path.splitext(suggest_name or f"result{default_ext}")
    ext = ext or default_ext
    return os.path.join("/tmp", f"{base}_{st.session_state.SID}_{uuid4().hex[:8]}{ext}")

@st.cache_data(ttl=1800, show_spinner=False)
def _read_excel_cached(file_or_path, sheet_name=0, engine=None):
    return pd.read_excel(file_or_path, sheet_name=sheet_name, engine=engine)

# App configuration
APP_CONFIG = {
    "app_title": "å¸‚åœºæ´å¯Ÿå°ç¨‹åº",
    "author": "æµ·ç¿¼IDCå›¢é˜Ÿ",
    "version": "v1.2.0",
    "contact": "idc@oceanwing.com",
    "company": "Anker Oceanwing Inc."
}

# === Shared UI/render helpers ===
def render_app_header(emoji_title: str, subtitle: str):
    st.markdown(f"""
    <div style="background: linear-gradient(135deg, #00a6e4 0%, #0088c2 100%); padding: 2rem; border-radius: 10px; margin-bottom: 2rem; box-shadow: 0 4px 6px rgba(0,0,0,0.1);">
        <h2 style="color: white; margin: 0; display: flex; align-items: center;">
            {emoji_title}
        </h2>
        <p style="color: rgba(255,255,255,0.9); margin-top: 0.5rem;">{subtitle}</p>
    </div>
    """, unsafe_allow_html=True)

def get_timestamp() -> str:
    return datetime.now().strftime("%Y-%m-%d_%H-%M-%S")

def save_df_to_buffer(df: pd.DataFrame) -> io.BytesIO:
    buffer = io.BytesIO()
    df.to_excel(buffer, index=False, engine="openpyxl")
    buffer.seek(0)
    return buffer

def save_workbook_to_buffer(wb: Workbook) -> io.BytesIO:
    buffer = io.BytesIO()
    wb.save(buffer)
    buffer.seek(0)
    return buffer

def render_download_section(
    buffer: io.BytesIO,
    file_name: str,
    mime_type: str,
    download_label: str,
    key_prefix: str,
    has_save: bool = False,
    save_func: Callable[[], None] | None = None,
    save_path: str | None = None,
):
    if has_save:
        col_d, col_s = st.columns(2)
        with col_d:
            st.download_button(
                label=download_label,
                data=buffer,
                file_name=file_name,
                mime=mime_type,
                key=f"{key_prefix}_download",
                use_container_width=True,
            )
        with col_s:
            if st.checkbox("ğŸ’¾ åŒæ—¶ä¿å­˜åˆ° /tmp ç›®å½•", key=f"{key_prefix}_save"):
                if save_func:
                    save_func()
                st.info(f"ğŸ“ æ–‡ä»¶å·²ä¿å­˜åˆ° {save_path}")
    else:
        st.download_button(
            label=download_label,
            data=buffer,
            file_name=file_name,
            mime=mime_type,
            key=f"{key_prefix}_download",
            use_container_width=True,
        )

# === Shared ZIP processors ===
def read_file_merge(file_path: str) -> pd.DataFrame | None:
    ext = os.path.splitext(file_path)[1].lower()
    if ext == ".csv":
        return pd.read_csv(file_path)
    engine = "openpyxl" if ext == ".xlsx" else "xlrd" if ext == ".xls" else None
    if engine:
        return _read_excel_cached(file_path, engine=engine)
    return None

def read_file_clean(file_path: str) -> pd.DataFrame | None:
    ext = os.path.splitext(file_path)[1].lower()
    if ext == ".csv":
        return pd.read_csv(file_path, header=None)
    engine = "openpyxl" if ext == ".xlsx" else "xlrd" if ext == ".xls" else None
    if engine:
        return pd.read_excel(file_path, header=None, engine=engine)
    return None

def write_processed_file(df: pd.DataFrame, path: str, ext: str):
    if ext == ".csv":
        df.to_csv(path, index=False)
    else:
        df.to_excel(path, index=False, engine="openpyxl")

def process_zip_files(
    uploaded_file,
    read_cb: Callable[[str], pd.DataFrame | None],
    process_cb: Callable[[pd.DataFrame, str, str], Any],
) -> List[Any]:
    with tempfile.TemporaryDirectory() as temp_dir:
        zip_path = os.path.join(temp_dir, uploaded_file.name)
        with open(zip_path, "wb") as f:
            f.write(uploaded_file.getbuffer())
        with zipfile.ZipFile(zip_path, "r") as z:
            z.extractall(temp_dir)
        files = [f for f in os.listdir(temp_dir) if f.lower().endswith((".xlsx", ".xls", ".csv"))]
        if not files:
            st.warning("ğŸ“‚ å‹ç¼©æ–‡ä»¶ä¸­æœªæ‰¾åˆ°ä»»ä½• Excel æˆ– CSV æ–‡ä»¶")
            return []
        results = []
        pb = st.progress(0)
        status = st.empty()
        for i, f in enumerate(files):
            status.text(f"æ­£åœ¨å¤„ç†: {f} ({i+1}/{len(files)})")
            fp = os.path.join(temp_dir, f)
            try:
                df = read_cb(fp)
                if df is None:
                    raise ValueError("ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼")
                results.append(process_cb(df, f, temp_dir))
            except Exception as e:
                st.error(f"âŒ å¤„ç†æ–‡ä»¶ {f} å¤±è´¥: {e}")
            pb.progress((i + 1) / len(files))
        status.empty()
        pb.empty()
        return results

# å¤„ç†ä»·æ ¼åˆ—
def process_price_columns(df):
    df = df.copy()
    price_pattern = re.compile(r'\$(\d+\.\d+)(?:\s*-\s*\$\d+\.\d+)?')
    def extract_price(price_str):
        if not isinstance(price_str, str):
            return price_str
        price_str = price_str.replace(',', '')
        match = price_pattern.match(price_str)
        return float(match.group(1)) if match else float(price_str.replace('$', ''))
    price_columns = [col for col in df.columns if 'å”®ä»·' in col]
    for column in price_columns:
        df[column] = df[column].apply(extract_price)
    return df

# åˆå¹¶æ•°æ®è¡¨æ ¼åŠŸèƒ½
def merge_data_app():
    render_app_header("ğŸ“Š MI/SI - åˆå¹¶æ•°æ®è¡¨æ ¼", "å°†å¤šä¸ªExcelæ–‡ä»¶åˆå¹¶ä¸ºä¸€ä¸ªç»Ÿä¸€çš„æ•°æ®è¡¨æ ¼")
    col1, col2 = st.columns([2, 1])
    with col1:
        uploaded_file = st.file_uploader(
            "é€‰æ‹©ä¸€ä¸ª .zip æ–‡ä»¶(åŒ…å«éœ€è¦åˆå¹¶çš„ Excel æ–‡ä»¶)",
            type=["zip"],
            accept_multiple_files=False,
            key="merge_files",
            help="æ”¯æŒåŒ…å«.xlsxã€.xlsã€.csvæ ¼å¼çš„ZIPå‹ç¼©åŒ…",
        )
    with col2:
        save_filename = st.text_input(
            "è¾“å‡ºæ–‡ä»¶å",
            value="merged_output.xlsx",
            key="merge_save",
            help="è¯·è¾“å…¥åˆå¹¶åçš„æ–‡ä»¶å",
        )
    st.divider()
    execute_btn = st.button("ğŸš€ å¼€å§‹åˆå¹¶", key="merge_button", use_container_width=True)
    if execute_btn:
        if not uploaded_file or not save_filename:
            st.warning("âš ï¸ è¯·ç¡®ä¿å·²é€‰æ‹© .zip æ–‡ä»¶å¹¶è¾“å…¥æ–‡ä»¶å")
            return
        with st.spinner("ğŸ”„ æ­£åœ¨å¤„ç†æ–‡ä»¶ï¼Œè¯·ç¨å€™..."):
            save_path = unique_tmp_path(save_filename)
            def cb_merge(df, fname, _):
                df["æ—¶é—´"] = os.path.splitext(fname)[0]
                return process_price_columns(df)
            df_list = process_zip_files(uploaded_file, read_file_merge, cb_merge)
            if not df_list:
                return
            status = st.empty()
            prog = st.progress(0)
            status.text("æ­£åœ¨åˆå¹¶æ•°æ®...")
            merged_df = pd.concat(df_list, ignore_index=True)
            merged_df = merged_df.loc[:, ~merged_df.columns.duplicated()]
            prog.progress(1.0)
            status.text("åˆå¹¶å®Œæˆ")
            status.empty()
            prog.empty()
            buffer = save_df_to_buffer(merged_df)
            st.success(f"âœ… æˆåŠŸåˆå¹¶ {len(df_list)} ä¸ªæ–‡ä»¶ï¼Œå…± {len(merged_df)} è¡Œæ•°æ®")
            save_func = lambda: merged_df.to_excel(save_path, index=False, engine="openpyxl")
            render_download_section(
                buffer,
                os.path.basename(save_filename),
                "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                "ğŸ“¥ ä¸‹è½½åˆå¹¶åçš„æ–‡ä»¶",
                "merged",
                has_save=True,
                save_func=save_func,
                save_path=save_path,
            )

# æœç´¢æµé‡æ´å¯Ÿï¼ˆæºæ•°æ®ï¼‰
def analyze_search_rows(df: pd.DataFrame, params: List[tuple]):
    punct = str.maketrans("", "", '!"#$%&\'()*+,-./:;<=>?@[\\]^_`{|}~')
    brands = df["å“ç‰Œåç§°"].dropna().unique()
    for p, _ in params:
        df[p] = ""
    df["å“ç‰Œ"] = ""
    df["ç‰¹æ€§å‚æ•°"] = ""
    results = []
    brand_words = []
    pb = st.progress(0)
    status = st.empty()
    for idx, row in df.iterrows():
        status.text(f"æ­£åœ¨åˆ†æç¬¬ {idx+1}/{len(df)} æ¡æ•°æ®...")
        sword = str(row["æœç´¢è¯"]).lower()
        vol = row["æœç´¢é‡"] if pd.notna(row["æœç´¢é‡"]) else 0
        m_brands = []
        for b in brands:
            b_low = str(b).lower()
            if len(b_low) <= 5:
                if re.search(rf"\b{re.escape(b_low)}\b", sword):
                    m_brands.append(b_low)
            else:
                norms = [
                    b_low,
                    b_low.translate(punct),
                    b_low.replace(" ", ""),
                    b_low.translate(punct).replace(" ", ""),
                ]
                if any(n in sword for n in norms):
                    m_brands.append(b_low)
        df.at[idx, "å“ç‰Œ"] = ",".join(set(m_brands))
        m_params = []
        for p_name, p_vals in params:
            m_vals = [str(v).lower() for v in p_vals if str(v).lower() in sword]
            df.at[idx, p_name] = ",".join(set(m_vals))
            m_params.extend(m_vals)
        df.at[idx, "ç‰¹æ€§å‚æ•°"] = ",".join(set(m_params))
        if m_brands:
            results.append("Branded KWs")
            for b in set(m_brands):
                brand_words.append({"å“ç‰Œåç§°": b, "æœç´¢é‡": vol})
        else:
            results.append("Non-Branded KWs")
        pb.progress((idx + 1) / len(df))
    status.empty()
    pb.empty()
    df["è¯æ€§"] = results
    return df, results

def search_insight_app():
    render_app_header("ğŸ” SI - æœç´¢æµé‡æ´å¯Ÿ", "åˆ†ææœç´¢å…³é”®è¯ï¼Œè¯†åˆ«å“ç‰Œè¯ä¸éå“ç‰Œè¯")
    st.markdown("#### ğŸ“‹ æ­¥éª¤ 1: ä¸‹è½½æ•°æ®æ¨¡æ¿")
    tmpl = pd.DataFrame(columns=["æœç´¢è¯", "æœç´¢é‡", "å“ç‰Œåç§°"])
    buf = io.BytesIO()
    tmpl.to_excel(buf, index=False)
    buf.seek(0)
    st.download_button(
        "ğŸ“¥ ä¸‹è½½Excelæ¨¡æ¿",
        buf,
        "template.xlsx",
        "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        key="download_template",
        use_container_width=True,
    )
    st.divider()
    st.markdown("#### ğŸ“¤ æ­¥éª¤ 2: ä¸Šä¼ å¡«å†™å¥½çš„æ•°æ®æ–‡ä»¶")
    col1, col2 = st.columns([2, 1])
    with col1:
        uploaded_file = st.file_uploader("é€‰æ‹©æ•°æ®æ–‡ä»¶", type=["xlsx", "xls"], key="data_file")
    with col2:
        save_filename = st.text_input("è¾“å‡ºæ–‡ä»¶å", "search_insight_result.xlsx", key="save_folder")
    st.divider()
    st.markdown("#### âš™ï¸ æ­¥éª¤ 3: è¾“å…¥äº§å“å‚æ•°(å¯é€‰)")
    col1, col2 = st.columns(2)
    with col1:
        param_names = st.text_input("å‚æ•°å(ç”¨é€—å·åˆ†éš”)", placeholder="ä¾‹å¦‚: é¢œè‰²,å°ºå¯¸,æè´¨", key="param_names")
    with col2:
        param_values = st.text_area(
            "å…·ä½“å‚æ•°(æ¯è¡Œä¸€ä¸ªå‚æ•°ç»„,ç”¨é€—å·åˆ†éš”)",
            placeholder="ä¾‹å¦‚:\nçº¢,è“,ç»¿\nå°,ä¸­,å¤§",
            key="param_values",
            height=100,
        )
    st.divider()
    execute_btn = st.button("ğŸš€ å¼€å§‹åˆ†æ", key="execute_button", use_container_width=True)
    if execute_btn:
        if not uploaded_file or not save_filename:
            st.warning("âš ï¸ è¯·ç¡®ä¿å·²ä¸Šä¼ æ•°æ®æ–‡ä»¶å¹¶è¾“å…¥è¾“å‡ºæ–‡ä»¶å")
            return
        with st.spinner("ğŸ”„ æ­£åœ¨åˆ†ææ•°æ®ï¼Œè¯·ç¨å€™..."):
            save_path = unique_tmp_path(save_filename)
            df = _read_excel_cached(uploaded_file)
            if df.empty:
                st.warning("ğŸ“‚ ä¸Šä¼ çš„æ–‡ä»¶ä¸ºç©ºï¼Œè¯·æ£€æŸ¥æ•°æ®æ–‡ä»¶")
                return
            p_params = []
            if param_names and param_values:
                names = [n.strip() for n in re.split(r"[,\uff0c]", param_names) if n.strip()]
                vals = []
                for line in param_values.split("\n"):
                    vs = [v.strip() for v in re.split(r"[,\uff0c]", line) if v.strip()]
                    if vs:
                        vals.append(vs)
                p_params = list(zip(names, vals)) if len(names) == len(vals) else []
            df, kw_types = analyze_search_rows(df, p_params)
            branded = kw_types.count("Branded KWs")
            non_branded = len(kw_types) - branded
            status = st.empty()
            prog = st.progress(0)
            status.text("æ­£åœ¨ä¿å­˜åˆ°Excel...")
            prog.progress(0.5)
            wb = Workbook()
            if "Sheet" in wb.sheetnames:
                wb.remove(wb["Sheet"])
            ws = wb.create_sheet("æºæ•°æ®")
            for r in dataframe_to_rows(df, index=False, header=True):
                ws.append(r)
            prog.progress(1.0)
            status.text("ä¿å­˜å®Œæˆ")
            status.empty()
            prog.empty()
            buffer = save_workbook_to_buffer(wb)
            ts = get_timestamp()
            out_name = f"result_{ts}.xlsx"
            out_path = os.path.join("/tmp", out_name)
            st.success(f"âœ… åˆ†æå®Œæˆ! å“ç‰Œè¯: {branded} æ¡ | éå“ç‰Œè¯: {non_branded} æ¡")
            save_func = lambda: wb.save(out_path)
            render_download_section(
                buffer,
                out_name,
                "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                "ğŸ“¥ ä¸‹è½½å¤„ç†ç»“æœ",
                "result",
                has_save=True,
                save_func=save_func,
                save_path=out_path,
            )

# å¯è§†åŒ–å…±äº«
def aggregate_top_n(df, value_col, name_col, top_n=10):
    df = df.copy()
    df[name_col] = df[name_col].astype(str)
    df = df.sort_values(by=value_col, ascending=False).reset_index(drop=True)
    if len(df) > top_n:
        top_df = df.iloc[:top_n]
        others = df.iloc[top_n:][value_col].sum()
        others_row = pd.DataFrame([{name_col: "Others", value_col: others}])
        df = pd.concat([top_df[[name_col, value_col]], others_row], ignore_index=True)
    return df[[name_col, value_col]]

def pie_chart(df, value_col, name_col, title):
    df = df.copy()
    df[name_col] = df[name_col].astype(str)
    df = df.sort_values(by=value_col, ascending=False).reset_index(drop=True)
    if "Others" in df[name_col].values:
        order = [n for n in df[name_col] if n != "Others"] + ["Others"]
        df[name_col] = pd.Categorical(df[name_col], categories=order, ordered=True)
    palette = [
        "#4C8EDA", "#FFA14E", "#F25C5C", "#6BD0C1", "#58C27D", "#F7C948",
        "#B685D6", "#FF90B3", "#BC8D6E", "#C9C9C9", "#81D3EB",
    ]
    fig = px.pie(
        df,
        values=value_col,
        names=name_col,
        title=title,
        color_discrete_sequence=palette,
    )
    fig.update_traces(textinfo="label+percent", sort=False)
    fig.update_layout(
        height=900,
        legend=dict(orientation="v", x=0.8, y=0.5, font=dict(size=16)),
        margin=dict(l=20, r=150, t=50, b=50),
        font=dict(size=16),
    )
    st.plotly_chart(fig, use_container_width=True)

def search_insight_viz_app():
    render_app_header("ğŸ“ˆ SI - æœç´¢æµé‡æ´å¯Ÿ: èšåˆå’Œå¯è§†åŒ–", "ç”Ÿæˆå¤šç»´åº¦æ•°æ®åˆ†ææŠ¥è¡¨å’Œå¯è§†åŒ–å›¾è¡¨")
    col1, col2 = st.columns([2, 1])
    with col1:
        uploaded_file = st.file_uploader(
            "é€‰æ‹©åŒ…å«æºæ•°æ®çš„ Excel æ–‡ä»¶(å®Œæˆæ£€æŸ¥ç¡®è®¤æ— è¯¯)",
            type=["xlsx", "xls"],
            key="viz_data_file",
        )
    with col2:
        save_filename = st.text_input("è¾“å‡ºæ–‡ä»¶å", "viz_result.xlsx", key="viz_save_folder")
    st.divider()
    execute_btn = st.button("ğŸš€ å¼€å§‹å¯è§†åŒ–", key="viz_execute_button", use_container_width=True)
    if execute_btn:
        if not uploaded_file or not save_filename:
            st.warning("âš ï¸ è¯·ç¡®ä¿å·²ä¸Šä¼ æ•°æ®æ–‡ä»¶å¹¶è¾“å…¥è¾“å‡ºæ–‡ä»¶å")
            return
        with st.spinner("ğŸ”„ æ­£åœ¨ç”Ÿæˆå¯è§†åŒ–æŠ¥è¡¨ï¼Œè¯·ç¨å€™..."):
            save_path = unique_tmp_path(save_filename)
            df = _read_excel_cached(uploaded_file, sheet_name="æºæ•°æ®")
            if df.empty:
                st.warning("ğŸ“‚ ä¸Šä¼ çš„æ–‡ä»¶ä¸ºç©ºæˆ–ä¸åŒ…å«'æºæ•°æ®'å·¥ä½œè¡¨ï¼Œè¯·æ£€æŸ¥æ•°æ®æ–‡ä»¶")
                return
            # Brand aggregation
            brand_words = []
            b_status = st.empty()
            b_prog = st.progress(0)
            b_status.text("æ­£åœ¨å¤„ç†å“ç‰Œè¯...")
            step = max(1, len(df) // 10)
            for idx, row in df.iterrows():
                vol = row["æœç´¢é‡"] if pd.notna(row["æœç´¢é‡"]) else 0
                brands = [b.strip() for b in str(row["å“ç‰Œ"]).split(",") if b.strip()]
                for b in brands:
                    brand_words.append({"å“ç‰Œåç§°": b, "æœç´¢é‡": vol})
                if (idx + 1) % step == 0 or idx == len(df) - 1:
                    b_prog.progress((idx + 1) / len(df))
            brand_df = pd.DataFrame()
            if brand_words:
                brand_df = pd.DataFrame(brand_words).groupby("å“ç‰Œåç§°", as_index=False)["æœç´¢é‡"].sum()
                brand_df = aggregate_top_n(brand_df, "æœç´¢é‡", "å“ç‰Œåç§°")
            b_status.text("å“ç‰Œè¯å¤„ç†å®Œæˆ")
            b_prog.empty()
            b_status.empty()
            # Param aggregation (single pass)
            excluded = {"æœç´¢è¯", "æœç´¢é‡", "å“ç‰Œåç§°", "å“ç‰Œ", "ç‰¹æ€§å‚æ•°", "è¯æ€§"}
            param_cols = [c for c in df.columns if c not in excluded]
            param_heats: Dict[str, List[Dict]] = {c: [] for c in param_cols}
            p_status = st.empty()
            p_prog = st.progress(0)
            p_status.text("æ­£åœ¨å¤„ç†å‚æ•°...")
            for idx, row in df.iterrows():
                vol = row["æœç´¢é‡"] if pd.notna(row["æœç´¢é‡"]) else 0
                for c in param_cols:
                    val = str(row[c]) if pd.notna(row[c]) else ""
                    for v in [v.strip() for v in val.split(",") if v.strip()]:
                        param_heats[c].append({"å‚æ•°å€¼": v, "æœç´¢é‡": vol})
                if (idx + 1) % step == 0 or idx == len(df) - 1:
                    p_prog.progress((idx + 1) / len(df))
            p_status.text("å‚æ•°å¤„ç†å®Œæˆ")
            p_prog.empty()
            p_status.empty()
            # Traffic structure
            traffic_df = df[["è¯æ€§", "æœç´¢é‡"]].groupby("è¯æ€§", as_index=False)["æœç´¢é‡"].sum()
            traffic_df = aggregate_top_n(traffic_df, "æœç´¢é‡", "è¯æ€§")
            # Workbook
            s_status = st.empty()
            s_prog = st.progress(0)
            s_status.text("æ­£åœ¨ç”ŸæˆExcelå·¥ä½œç°¿...")
            s_prog.progress(0.3)
            wb = Workbook()
            if "Sheet" in wb.sheetnames:
                wb.remove(wb["Sheet"])
            ws = wb.create_sheet("æºæ•°æ®")
            for r in dataframe_to_rows(df, index=False, header=True):
                ws.append(r)
            s_prog.progress(0.6)
            if not brand_df.empty:
                ws = wb.create_sheet("å“ç‰Œè¯æ‹†è§£")
                for r in dataframe_to_rows(brand_df, index=False, header=True):
                    ws.append(r)
            s_prog.progress(0.7)
            param_dfs: Dict[str, pd.DataFrame] = {}
            active_params = [c for c in param_cols if param_heats[c]]
            for i, c in enumerate(active_params):
                heats = param_heats[c]
                if heats:
                    pdf = pd.DataFrame(heats).groupby("å‚æ•°å€¼", as_index=False)["æœç´¢é‡"].sum()
                    pdf = aggregate_top_n(pdf, "æœç´¢é‡", "å‚æ•°å€¼")
                    param_dfs[c] = pdf
                    clean = re.sub(r"[\/*?[\]]", "", c)[:31]
                    ws = wb.create_sheet(f"{clean}æ‹†è§£")
                    for r in dataframe_to_rows(pdf, index=False, header=True):
                        ws.append(r)
                s_prog.progress(0.7 + 0.3 * (i + 1) / max(1, len(active_params)))
            if not traffic_df.empty:
                ws = wb.create_sheet("å“ç±»æµé‡ç»“æ„")
                for r in dataframe_to_rows(traffic_df, index=False, header=True):
                    ws.append(r)
            s_prog.progress(1.0)
            s_status.text("å·¥ä½œç°¿ç”Ÿæˆå®Œæˆ")
            s_status.empty()
            s_prog.empty()
            buffer = save_workbook_to_buffer(wb)
            st.success("âœ… æ•°æ®å¤„ç†å®Œæˆï¼Œæ­£åœ¨ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
            st.markdown("### ğŸ“Š æ•°æ®å¯è§†åŒ–")
            if not brand_df.empty:
                pie_chart(brand_df, "æœç´¢é‡", "å“ç‰Œåç§°", "å“ç‰Œè¯æ‹†è§£")
            for c in param_cols:
                if c in param_dfs:
                    pie_chart(param_dfs[c], "æœç´¢é‡", "å‚æ•°å€¼", f"{c} å‚æ•°æœç´¢é‡åˆ†å¸ƒ")
            if not traffic_df.empty:
                pie_chart(traffic_df, "æœç´¢é‡", "è¯æ€§", "æµé‡ç»“æ„")
            st.divider()
            ts = get_timestamp()
            out_name = f"viz_result_{ts}.xlsx"
            out_path = os.path.join("/tmp", out_name)
            save_func = lambda: wb.save(out_path)
            render_download_section(
                buffer,
                out_name,
                "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                "ğŸ“¥ ä¸‹è½½å®Œæ•´æŠ¥è¡¨",
                "viz",
                has_save=True,
                save_func=save_func,
                save_path=out_path,
            )

# æ•°æ®æ¸…ç†
def data_clean_app():
    render_app_header("ğŸ§¹ DC - æ•°æ®æ¸…ç†: åˆ é™¤ç¬¬ä¸€è¡Œ", "æ‰¹é‡åˆ é™¤Excel/CSVæ–‡ä»¶çš„ç¬¬ä¸€è¡Œæ•°æ®å¹¶é‡æ–°æ‰“åŒ…")
    col1, col2 = st.columns([2, 1])
    with col1:
        uploaded_file = st.file_uploader(
            "é€‰æ‹©ä¸€ä¸ª .zip æ–‡ä»¶(åŒ…å« XLSX æˆ– CSV æ–‡ä»¶)",
            type=["zip"],
            key="clean_files",
        )
    with col2:
        output_filename = st.text_input("è¾“å‡ºæ–‡ä»¶å", "cleaned_files.zip", key="clean_save")
    st.divider()
    execute_btn = st.button("ğŸš€ å¼€å§‹æ¸…ç†", key="clean_button", use_container_width=True)
    if execute_btn:
        if not uploaded_file or not output_filename:
            st.warning("âš ï¸ è¯·ç¡®ä¿å·²é€‰æ‹© .zip æ–‡ä»¶å¹¶è¾“å…¥è¾“å‡ºæ–‡ä»¶å")
            return
        with st.spinner("ğŸ”„ æ­£åœ¨æ¸…ç†æ–‡ä»¶ï¼Œè¯·ç¨å€™..."):
            def cb_clean(df, fname, tdir):
                df = df.iloc[1:].reset_index(drop=True)
                out_path = os.path.join(tdir, f"cleaned_{fname}")
                ext = os.path.splitext(fname)[1].lower()
                write_processed_file(df, out_path, ext)
                return out_path
            processed = process_zip_files(uploaded_file, read_file_clean, cb_clean)
            if not processed:
                return
            status = st.empty()
            prog = st.progress(0)
            status.text("æ­£åœ¨æ‰“åŒ…ZIPæ–‡ä»¶...")
            buffer = io.BytesIO()
            with zipfile.ZipFile(buffer, "w", zipfile.ZIP_DEFLATED) as nz:
                for i, p in enumerate(processed):
                    arc = os.path.basename(p).replace("cleaned_", "")
                    nz.write(p, arc)
                    prog.progress((i + 1) / len(processed))
            buffer.seek(0)
            status.text("æ‰“åŒ…å®Œæˆ")
            status.empty()
            prog.empty()
            st.success(f"âœ… æˆåŠŸæ¸…ç† {len(processed)} ä¸ªæ–‡ä»¶")
            render_download_section(
                buffer,
                output_filename,
                "application/zip",
                "ğŸ“¥ ä¸‹è½½æ¸…ç†åçš„ ZIP æ–‡ä»¶",
                "cleaned",
                has_save=False,
            )

# ä¸»åº”ç”¨ç¨‹åº
def main():
    st.set_page_config(page_title=APP_CONFIG["app_title"], layout="wide", page_icon="ğŸ“Š", initial_sidebar_state="collapsed")
    st.markdown("""
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap');
        html, body, [class*="css"] {font-family: 'Inter', 'Segoe UI', sans-serif;}
        .main {background: linear-gradient(135deg, #f5f7fa 0%, #e9ecef 100%);}
        h1, h2, h3, h4, h5, h6 {color: #ffffff !important; font-weight: 600 !important;}
        .stButton > button {
            background: linear-gradient(135deg, #00a6e4 0%, #0088c2 100%);
            color: white; border: none; border-radius: 8px; padding: 0.6rem 1.5rem;
            font-weight: 600; font-size: 15px; transition: all 0.3s ease;
            box-shadow: 0 4px 6px rgba(0, 166, 228, 0.2);
        }
        .stButton > button:hover {
            background: linear-gradient(135deg, #0088c2 0%, #006a99 100%);
            box-shadow: 0 6px 12px rgba(0, 166, 228, 0.3); transform: translateY(-2px);
        }
        .stDownloadButton > button {background: linear-gradient(135deg, #00a6e4 0%, #0088c2 100%);
            color: white; border: none; border-radius: 8px; padding: 0.6rem 1.5rem;
            font-weight: 600; font-size: 15px; transition: all 0.3s ease;
            box-shadow: 0 4px 6px rgba(0, 166, 228, 0.2);
        }
        .stDownloadButton > button:hover {
            background: linear-gradient(135deg, #0088c2 0%, #006a99 100%);
            box-shadow: 0 6px 12px rgba(0, 166, 228, 0.3); transform: translateY(-2px);
        }
        .stFileUploader {background: white; border-radius: 10px; padding: 1.5rem; box-shadow: 0 2px 8px rgba(0,0,0,0.08);}
        [data-testid="stFileUploadDropzone"] {border: 2px dashed #00a6e4; border-radius: 8px; background: #f8fcff;}
        .stTextInput > div > div > input, .stTextArea > div > div > textarea {
            border: 2px solid #e0e0e0; border-radius: 8px; padding: 0.6rem; transition: all 0.3s ease; font-size: 14px;
        }
        .stTextInput > div > div > input:focus, .stTextArea > div > div > textarea:focus {
            border-color: #00a6e4; box-shadow: 0 0 0 3px rgba(0, 166, 228, 0.1);
        }
        .stProgress > div > div > div > div {background: linear-gradient(90deg, #00a6e4 0%, #0088c2 100%);}
        .stSuccess {background: linear-gradient(135deg, #d4edda 0%, #c3e6cb 100%); border-left: 4px solid #28a745; border-radius: 8px; padding: 1rem;}
        .stError {background: linear-gradient(135deg, #f8d7da 0%, #f5c6cb 100%); border-left: 4px solid #dc3545; border-radius: 8px; padding: 1rem;}
        .stWarning {background: linear-gradient(135deg, #fff3cd 0%, #ffeaa7 100%); border-left: 4px solid #ffc107; border-radius: 8px; padding: 1rem;}
        .stInfo {background: linear-gradient(135deg, #d1ecf1 0%, #bee5eb 100%); border-left: 4px solid #00a6e4; border-radius: 8px; padding: 1rem;}
        div[data-testid="column"] {background: white; padding: 1rem; border-radius: 10px; box-shadow: 0 2px 8px rgba(0,0,0,0.05);}
        .js-plotly-plot {border-radius: 10px; box-shadow: 0 4px 12px rgba(0,0,0,0.1);}
    </style>
    """, unsafe_allow_html=True)
    st.markdown(f"""
    <div style="background: linear-gradient(135deg, #00a6e4 0%, #0088c2 100%); padding: 2.5rem 2rem; border-radius: 15px; margin-bottom: 2rem; box-shadow: 0 8px 16px rgba(0,0,0,0.15);">
        <h1 style="color: white; margin: 0; font-size: 2.5rem; font-weight: 700;">ğŸ“Š å¸‚åœºæ´å¯Ÿå°ç¨‹åº</h1>
        <div style="display: flex; gap: 2rem; margin-top: 1rem; flex-wrap: wrap;">
            <span style="color: rgba(255,255,255,0.95); font-size: 14px;"><strong>ç‰ˆæœ¬:</strong> {APP_CONFIG["version"]}</span>
            <span style="color: rgba(255,255,255,0.95); font-size: 14px;"><strong>ä½œè€…:</strong> {APP_CONFIG["author"]}</span>
            <span style="color: rgba(255,255,255,0.95); font-size: 14px;"><strong>å…¬å¸:</strong> {APP_CONFIG["company"]}</span>
            <span style="color: rgba(255,255,255,0.95); font-size: 14px;"><strong>è”ç³»:</strong> {APP_CONFIG["contact"]}</span>
        </div>
    </div>
    """, unsafe_allow_html=True)
    st.markdown("""
    <div style="background: white; padding: 1.5rem; border-radius: 10px; margin-bottom: 2rem; box-shadow: 0 2px 8px rgba(0,0,0,0.08);">
        <h3 style="margin-top: 0; color: #333;">ğŸ¯ åŠŸèƒ½å¯¼èˆª</h3>
        <p style="color: #666; margin-bottom: 0;">é€‰æ‹©ä¸‹æ–¹åŠŸèƒ½æ¨¡å—å¼€å§‹æ‚¨çš„æ•°æ®åˆ†æä¹‹æ—…</p>
    </div>
    """, unsafe_allow_html=True)
    tabs = st.tabs(["ğŸ“Š åˆå¹¶æ•°æ®è¡¨æ ¼", "ğŸ” æœç´¢æµé‡æ´å¯Ÿ", "ğŸ“ˆ æµé‡å¯è§†åŒ–åˆ†æ", "ğŸ§¹ æ•°æ®æ¸…ç†å·¥å…·"])
    with tabs[0]:
        merge_data_app()
    with tabs[1]:
        search_insight_app()
    with tabs[2]:
        search_insight_viz_app()
    with tabs[3]:
        data_clean_app()
    st.divider()
    st.markdown("""
    <div style="text-align: center; color: #666; padding: 2rem 0;">
        <p style="margin: 0;">Â© Anker Oceanwing Inc. | æµ·ç¿¼IDCå›¢é˜Ÿ</p>
        <p style="margin: 0.5rem 0 0 0; font-size: 13px;">å¸‚åœºæ´å¯Ÿå°ç¨‹åº v1.2.0 - è®©æ•°æ®åˆ†ææ›´ç®€å•</p>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()
