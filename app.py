import streamlit as st
import pandas as pd
import os
import re
from datetime import datetime
import io
import zipfile
import tempfile
from openpyxl import Workbook
from openpyxl.utils.dataframe import dataframe_to_rows
import plotly.express as px
from uuid import uuid4

# === Concurrency-safe session + helpers ===
if "SID" not in st.session_state:
    st.session_state.SID = uuid4().hex[:6]

def unique_tmp_path(suggest_name: str, default_ext: str = ".xlsx") -> str:
    base, ext = os.path.splitext(suggest_name or f"result{default_ext}")
    ext = ext or default_ext
    return os.path.join("/tmp", f"{base}_{st.session_state.SID}_{uuid4().hex[:8]}{ext}")

@st.cache_data(ttl=1800, show_spinner=False)
def _read_excel_cached(file_or_path, sheet_name=0, engine=None):
    return pd.read_excel(file_or_path, sheet_name=sheet_name, engine=engine)

# App configuration
APP_CONFIG = {
    "app_title": "å¸‚åœºæ´å¯Ÿå°ç¨‹åº",
    "author": "æµ·ç¿¼IDCå›¢é˜Ÿ",
    "version": "v1.2.0",
    "contact": "idc@oceanwing.com",
    "company": "Anker Oceanwing Inc."
}

# å¤„ç†ä»·æ ¼åˆ—
def process_price_columns(df):
    df = df.copy()
    price_pattern = re.compile(r'\$(\d+\.\d+)(?:\s*-\s*\$\d+\.\d+)?')

    def extract_price(price_str):
        if not isinstance(price_str, str):
            return price_str
        price_str = price_str.replace(',', '')
        match = price_pattern.match(price_str)
        return float(match.group(1)) if match else float(price_str.replace('$', ''))

    price_columns = [col for col in df.columns if 'å”®ä»·' in col]
    for column in price_columns:
        df[column] = df[column].apply(extract_price)
    return df

# åˆå¹¶æ•°æ®è¡¨æ ¼åŠŸèƒ½
def merge_data_app():
    st.markdown("""
    <div style="background: linear-gradient(135deg, #00a6e4 0%, #0088c2 100%); padding: 2rem; border-radius: 10px; margin-bottom: 2rem; box-shadow: 0 4px 6px rgba(0,0,0,0.1);">
        <h2 style="color: white; margin: 0; display: flex; align-items: center;">
            ğŸ“Š MI/SI - åˆå¹¶æ•°æ®è¡¨æ ¼
        </h2>
        <p style="color: rgba(255,255,255,0.9); margin-top: 0.5rem;">å°†å¤šä¸ªExcelæ–‡ä»¶åˆå¹¶ä¸ºä¸€ä¸ªç»Ÿä¸€çš„æ•°æ®è¡¨æ ¼</p>
    </div>
    """, unsafe_allow_html=True)
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown("#### ğŸ“ ä¸Šä¼ æ–‡ä»¶")
        uploaded_file = st.file_uploader(
            "é€‰æ‹©ä¸€ä¸ª .zip æ–‡ä»¶(åŒ…å«éœ€è¦åˆå¹¶çš„ Excel æ–‡ä»¶)", 
            type=["zip"], 
            accept_multiple_files=False, 
            key="merge_files",
            help="æ”¯æŒåŒ…å«.xlsxã€.xlsã€.csvæ ¼å¼çš„ZIPå‹ç¼©åŒ…"
        )
    
    with col2:
        st.markdown("#### ğŸ’¾ è¾“å‡ºè®¾ç½®")
        save_filename = st.text_input(
            "è¾“å‡ºæ–‡ä»¶å", 
            value="merged_output.xlsx",
            key="merge_save",
            help="è¯·è¾“å…¥åˆå¹¶åçš„æ–‡ä»¶å"
        )
    
    st.markdown("---")
    
    col_btn1, col_btn2, col_btn3 = st.columns([1, 1, 2])
    with col_btn1:
        execute_btn = st.button("ğŸš€ å¼€å§‹åˆå¹¶", key="merge_button", use_container_width=True)
    
    if execute_btn:
        if not uploaded_file or not save_filename:
            st.warning("âš ï¸ è¯·ç¡®ä¿å·²é€‰æ‹© .zip æ–‡ä»¶å¹¶è¾“å…¥æ–‡ä»¶å")
            return
        
        with st.spinner("ğŸ”„ æ­£åœ¨å¤„ç†æ–‡ä»¶ï¼Œè¯·ç¨å€™..."):
            save_path = unique_tmp_path(save_filename)
            
            try:
                with tempfile.TemporaryDirectory() as temp_dir:
                    df_list = []
                    
                    file_extension = os.path.splitext(uploaded_file.name)[1].lower()
                    temp_file_path = os.path.join(temp_dir, uploaded_file.name)
                    
                    with open(temp_file_path, "wb") as f:
                        f.write(uploaded_file.getbuffer())
                    
                    if file_extension == '.zip':
                        with zipfile.ZipFile(temp_file_path, 'r') as zip_ref:
                            zip_ref.extractall(temp_dir)
                    
                    excel_files = [f for f in os.listdir(temp_dir) if f.endswith(('.xlsx', '.xls', '.csv'))]
                    
                    if not excel_files:
                        st.warning("ğŸ“‚ å‹ç¼©æ–‡ä»¶ä¸­æœªæ‰¾åˆ°ä»»ä½• Excel æˆ– CSV æ–‡ä»¶")
                        return
                    
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    
                    for idx, file_name in enumerate(excel_files):
                        file_path = os.path.join(temp_dir, file_name)
                        try:
                            status_text.text(f"æ­£åœ¨å¤„ç†: {file_name} ({idx+1}/{len(excel_files)})")
                            
                            if file_name.endswith('.xlsx'):
                                df = _read_excel_cached(file_path, engine='openpyxl')
                            elif file_name.endswith('.xls'):
                                df = _read_excel_cached(file_path, engine='xlrd')
                            elif file_name.endswith('.csv'):
                                df = pd.read_csv(file_path)
                            
                            df['æ—¶é—´'] = os.path.splitext(file_name)[0]
                            df = process_price_columns(df)
                            df_list.append(df)
                            
                            progress_bar.progress((idx + 1) / len(excel_files))
                        except Exception as e:
                            st.error(f"âŒ è¯»å–æ–‡ä»¶ {file_name} å¤±è´¥:{e}")
                            continue
                    
                    status_text.empty()
                    progress_bar.empty()
                    
                    if df_list:
                        # æ·»åŠ åˆå¹¶è¿›åº¦æ¡
                        merge_progress = st.progress(0)
                        merge_status = st.empty()
                        merge_status.text("æ­£åœ¨åˆå¹¶æ•°æ®...")
                        merged_df = pd.concat(df_list, ignore_index=True)
                        merged_df = merged_df.loc[:, ~merged_df.columns.duplicated()]
                        merge_progress.progress(1.0)
                        merge_status.text("åˆå¹¶å®Œæˆ")
                        merge_progress.empty()
                        merge_status.empty()
                        
                        buffer = io.BytesIO()
                        merged_df.to_excel(buffer, index=False, engine='openpyxl')
                        buffer.seek(0)
                        
                        st.success(f"âœ… æˆåŠŸåˆå¹¶ {len(df_list)} ä¸ªæ–‡ä»¶ï¼Œå…± {len(merged_df)} è¡Œæ•°æ®")
                        
                        col_download, col_save = st.columns(2)
                        with col_download:
                            st.download_button(
                                label="ğŸ“¥ ä¸‹è½½åˆå¹¶åçš„æ–‡ä»¶",
                                data=buffer,
                                file_name=os.path.basename(save_filename),
                                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                                key="download_merged",
                                use_container_width=True
                            )
                        with col_save:
                            if st.checkbox("ğŸ’¾ åŒæ—¶ä¿å­˜åˆ° /tmp ç›®å½•", key="save_merged"):
                                merged_df.to_excel(save_path, index=False, engine='openpyxl')
                                st.info(f"ğŸ“ æ–‡ä»¶å·²ä¿å­˜åˆ° {save_path}")
                    else:
                        st.warning("âš ï¸ æ²¡æœ‰å¯åˆå¹¶çš„æ•°æ®")
            except Exception as e:
                st.error(f"âŒ å¤„ç†å‹ç¼©æ–‡ä»¶æˆ–åˆå¹¶æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯:{e}")

# æœç´¢æµé‡æ´å¯ŸåŠŸèƒ½(ä»…ç”Ÿæˆæºæ•°æ®å·¥ä½œè¡¨)
def search_insight_app():
    st.markdown("""
    <div style="background: linear-gradient(135deg, #00a6e4 0%, #0088c2 100%); padding: 2rem; border-radius: 10px; margin-bottom: 2rem; box-shadow: 0 4px 6px rgba(0,0,0,0.1);">
        <h2 style="color: white; margin: 0; display: flex; align-items: center;">
            ğŸ” SI - æœç´¢æµé‡æ´å¯Ÿ
        </h2>
        <p style="color: rgba(255,255,255,0.9); margin-top: 0.5rem;">åˆ†ææœç´¢å…³é”®è¯ï¼Œè¯†åˆ«å“ç‰Œè¯ä¸éå“ç‰Œè¯</p>
    </div>
    """, unsafe_allow_html=True)
    
    # æ¨¡æ¿ä¸‹è½½åŒºåŸŸ
    st.markdown("#### ğŸ“‹ æ­¥éª¤ 1: ä¸‹è½½æ•°æ®æ¨¡æ¿")
    template_df = pd.DataFrame(columns=["æœç´¢è¯", "æœç´¢é‡", "å“ç‰Œåç§°"])
    buffer = io.BytesIO()
    template_df.to_excel(buffer, index=False)
    buffer.seek(0)
    
    col_template1, col_template2, col_template3 = st.columns([1, 1, 2])
    with col_template1:
        st.download_button(
            label="ğŸ“¥ ä¸‹è½½Excelæ¨¡æ¿",
            data=buffer,
            file_name="template.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            key="download_template",
            use_container_width=True
        )
    
    st.markdown("---")
    
    # æ•°æ®ä¸Šä¼ åŒºåŸŸ
    st.markdown("#### ğŸ“¤ æ­¥éª¤ 2: ä¸Šä¼ å¡«å†™å¥½çš„æ•°æ®æ–‡ä»¶")
    col1, col2 = st.columns([2, 1])
    
    with col1:
        uploaded_file = st.file_uploader(
            "é€‰æ‹©æ•°æ®æ–‡ä»¶", 
            type=["xlsx", "xls"], 
            key="data_file",
            help="è¯·ä¸Šä¼ æŒ‰æ¨¡æ¿å¡«å†™çš„Excelæ–‡ä»¶"
        )
    
    with col2:
        save_filename = st.text_input(
            "è¾“å‡ºæ–‡ä»¶å", 
            value="search_insight_result.xlsx",
            key="save_folder",
            help="è¯·è¾“å…¥è¾“å‡ºæ–‡ä»¶å"
        )
    
    st.markdown("---")
    
    # äº§å“å‚æ•°è¾“å…¥
    st.markdown("#### âš™ï¸ æ­¥éª¤ 3: è¾“å…¥äº§å“å‚æ•°(å¯é€‰)")
    
    col_param1, col_param2 = st.columns(2)
    with col_param1:
        param_names = st.text_input(
            "å‚æ•°å(ç”¨é€—å·åˆ†éš”)", 
            placeholder="ä¾‹å¦‚: é¢œè‰²,å°ºå¯¸,æè´¨",
            key="param_names",
            help="è¾“å…¥éœ€è¦åˆ†æçš„äº§å“å‚æ•°åç§°"
        )
    
    with col_param2:
        param_values = st.text_area(
            "å…·ä½“å‚æ•°(æ¯è¡Œä¸€ä¸ªå‚æ•°ç»„,ç”¨é€—å·åˆ†éš”)", 
            placeholder="ä¾‹å¦‚:\nçº¢,è“,ç»¿\nå°,ä¸­,å¤§",
            key="param_values",
            help="æ¯è¡Œå¯¹åº”ä¸€ä¸ªå‚æ•°çš„æ‰€æœ‰å¯èƒ½å€¼",
            height=100
        )
    
    st.markdown("---")
    
    # æ‰§è¡ŒæŒ‰é’®
    col_exec1, col_exec2, col_exec3 = st.columns([1, 1, 2])
    with col_exec1:
        execute_btn = st.button("ğŸš€ å¼€å§‹åˆ†æ", key="execute_button", use_container_width=True)
    
    if execute_btn:
        if not uploaded_file or not save_filename:
            st.warning("âš ï¸ è¯·ç¡®ä¿å·²ä¸Šä¼ æ•°æ®æ–‡ä»¶å¹¶è¾“å…¥è¾“å‡ºæ–‡ä»¶å")
            return
        
        with st.spinner("ğŸ”„ æ­£åœ¨åˆ†ææ•°æ®ï¼Œè¯·ç¨å€™..."):
            save_path = unique_tmp_path(save_filename)
            
            try:
                df = _read_excel_cached(uploaded_file)
                if df.empty:
                    st.warning("ğŸ“‚ ä¸Šä¼ çš„æ–‡ä»¶ä¸ºç©ºï¼Œè¯·æ£€æŸ¥æ•°æ®æ–‡ä»¶")
                    return
                
                # å¤„ç†äº§å“å‚æ•°(æ”¯æŒä¸­è‹±æ–‡é€—å·)
                product_parameters = []
                if param_names and param_values:
                    param_names_list = [name.strip() for name in re.split(r'[,\uff0c]', param_names) if name.strip()]
                    param_values_list = []
                    for v in param_values.split('\n'):
                        values = [val.strip() for val in re.split(r'[,\uff0c]', v) if val.strip()]
                        if values:
                            param_values_list.append(values)
                    product_parameters = list(zip(param_names_list, param_values_list)) if param_names_list and param_values_list else []
                
                # åˆå§‹åŒ–åˆ—
                df['å“ç‰Œ'] = ''
                df['ç‰¹æ€§å‚æ•°'] = ''
                for param_name, _ in product_parameters:
                    df[param_name] = ''
                
                results = []
                brand_words_list = []
                translator_punct = str.maketrans('', '', '!"#$%&\'()*+,-./:;<=>?@[\\]^_`{|}~')
                
                # å¤„ç†æœç´¢è¯
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                for index, row in df.iterrows():
                    status_text.text(f"æ­£åœ¨åˆ†æç¬¬ {index+1}/{len(df)} æ¡æ•°æ®...")
                    
                    search_word = str(row['æœç´¢è¯']).lower()
                    search_volumn = row['æœç´¢é‡'] if pd.notna(row['æœç´¢é‡']) else 0
                    
                    matched_brands = []
                    found_brand = False
                    for brand in df['å“ç‰Œåç§°'].dropna().unique():
                        brand_str = str(brand).lower()
                        if len(brand_str) <= 5:
                            pattern = rf'\b{re.escape(brand_str)}\b'
                            if re.search(pattern, search_word):
                                matched_brands.append(brand_str)
                                found_brand = True
                        else:
                            if brand_str in search_word or \
                               brand_str.translate(translator_punct) in search_word or \
                               brand_str.replace(' ', '') in search_word or \
                               brand_str.translate(translator_punct).replace(' ', '') in search_word:
                                matched_brands.append(brand_str)
                                found_brand = True
                    
                    df.at[index, 'å“ç‰Œ'] = ','.join(set(matched_brands))
                    
                    matched_params = []
                    for param_name, param_values in product_parameters:
                        matched_values = [str(param).lower() for param in param_values if str(param).lower() in search_word]
                        df.at[index, param_name] = ','.join(set(matched_values))
                        matched_params.extend(matched_values)
                    df.at[index, 'ç‰¹æ€§å‚æ•°'] = ','.join(set(matched_params))
                    
                    if found_brand:
                        results.append('Branded KWs')
                        for brand in matched_brands:
                            brand_words_list.append({'å“ç‰Œåç§°': brand, 'æœç´¢é‡': search_volumn})
                    else:
                        results.append('Non-Branded KWs')
                    
                    progress_bar.progress((index + 1) / len(df))
                
                df['è¯æ€§'] = results
                
                status_text.empty()
                progress_bar.empty()
                
                # æ·»åŠ ä¿å­˜è¿›åº¦æ¡
                save_progress = st.progress(0)
                save_status = st.empty()
                save_status.text("æ­£åœ¨ä¿å­˜åˆ°Excel...")
                save_progress.progress(0.5)
                
                # ä¿å­˜åˆ° Excel(ä»…æºæ•°æ®å·¥ä½œè¡¨)
                workbook = Workbook()
                if "Sheet" in workbook.sheetnames:
                    workbook.remove(workbook["Sheet"])
                
                ws_source = workbook.create_sheet('æºæ•°æ®')
                for r in dataframe_to_rows(df, index=False, header=True):
                    ws_source.append(r)
                
                timestamp = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')
                output_filename = f"result_{timestamp}.xlsx"
                output_path = os.path.join("/tmp", output_filename)
                
                buffer = io.BytesIO()
                workbook.save(buffer)
                buffer.seek(0)
                save_progress.progress(1.0)
                save_status.text("ä¿å­˜å®Œæˆ")
                save_progress.empty()
                save_status.empty()
                
                branded_count = results.count('Branded KWs')
                non_branded_count = results.count('Non-Branded KWs')
                
                st.success(f"âœ… åˆ†æå®Œæˆ! å“ç‰Œè¯: {branded_count} æ¡ | éå“ç‰Œè¯: {non_branded_count} æ¡")
                
                col_download, col_save = st.columns(2)
                with col_download:
                    st.download_button(
                        label="ğŸ“¥ ä¸‹è½½å¤„ç†ç»“æœ",
                        data=buffer,
                        file_name=output_filename,
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                        key="download_result",
                        use_container_width=True
                    )
                with col_save:
                    if st.checkbox("ğŸ’¾ åŒæ—¶ä¿å­˜åˆ° /tmp ç›®å½•", key="save_result"):
                        workbook.save(output_path)
                        st.info(f"ğŸ“ æ–‡ä»¶å·²ä¿å­˜åˆ° {output_path}")
            
            except Exception as e:
                st.error(f"âŒ å¤„ç†æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯:{e}")

# æœç´¢æµé‡æ´å¯Ÿå¯è§†åŒ–åŠŸèƒ½
def aggregate_top_n(df, value_col, name_col, top_n=10):
    df = df.copy()
    df[name_col] = df[name_col].astype(str)
    df = df.sort_values(by=value_col, ascending=False).reset_index(drop=True)

    if len(df) > top_n:
        top_df = df.iloc[:top_n]
        others_df = df.iloc[top_n:]
        others_total = others_df[value_col].sum()
        others_row = pd.DataFrame([{name_col: 'Others', value_col: others_total}])
        final_df = pd.concat([top_df[[name_col, value_col]], others_row], ignore_index=True)
    else:
        final_df = df[[name_col, value_col]]
    
    return final_df

def pie_chart(df, value_col, name_col, title):
    df = df.copy()

    df[name_col] = df[name_col].astype(str)
    df = df.sort_values(by=value_col, ascending=False).reset_index(drop=True)
    if 'Others' in df[name_col].values:
        categories = [name for name in df[name_col] if name != 'Others'] + ['Others']
        df[name_col] = pd.Categorical(df[name_col], categories=categories, ordered=True)
    else:
        df[name_col] = pd.Categorical(df[name_col], ordered=True)
    
    business_palette = [
        "#4C8EDA", "#FFA14E", "#F25C5C", "#6BD0C1", "#58C27D", "#F7C948",
        "#B685D6", "#FF90B3", "#BC8D6E", "#C9C9C9", "#81D3EB"
    ]

    fig = px.pie(
        df,
        values=value_col,
        names=name_col,
        title=title,
        category_orders={name_col: df[name_col].cat.categories.tolist()},
        color_discrete_sequence=business_palette
    )
    fig.update_traces(textinfo='label+percent', sort=False)

    fig.update_layout(
        height=900,
        legend=dict(orientation="v", x=0.8, y=0.5, font=dict(size=16)),
        margin=dict(l=20, r=150, t=50, b=50),
        font=dict(size=16)
    )

    st.plotly_chart(fig, use_container_width=True)

def search_insight_viz_app():
    st.markdown("""
    <div style="background: linear-gradient(135deg, #00a6e4 0%, #0088c2 100%); padding: 2rem; border-radius: 10px; margin-bottom: 2rem; box-shadow: 0 4px 6px rgba(0,0,0,0.1);">
        <h2 style="color: white; margin: 0; display: flex; align-items: center;">
            ğŸ“ˆ SI - æœç´¢æµé‡æ´å¯Ÿ: èšåˆå’Œå¯è§†åŒ–
        </h2>
        <p style="color: rgba(255,255,255,0.9); margin-top: 0.5rem;">ç”Ÿæˆå¤šç»´åº¦æ•°æ®åˆ†ææŠ¥è¡¨å’Œå¯è§†åŒ–å›¾è¡¨</p>
    </div>
    """, unsafe_allow_html=True)

    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown("#### ğŸ“ ä¸Šä¼ æºæ•°æ®æ–‡ä»¶")
        uploaded_file = st.file_uploader(
            "é€‰æ‹©åŒ…å«æºæ•°æ®çš„ Excel æ–‡ä»¶(å®Œæˆæ£€æŸ¥ç¡®è®¤æ— è¯¯)", 
            type=["xlsx", "xls"], 
            key="viz_data_file",
            help="è¯·ä¸Šä¼ åŒ…å«'æºæ•°æ®'å·¥ä½œè¡¨çš„Excelæ–‡ä»¶"
        )
    
    with col2:
        st.markdown("#### ğŸ’¾ è¾“å‡ºè®¾ç½®")
        save_filename = st.text_input(
            "è¾“å‡ºæ–‡ä»¶å", 
            value="viz_result.xlsx",
            key="viz_save_folder",
            help="è¯·è¾“å…¥è¾“å‡ºæ–‡ä»¶å"
        )

    st.markdown("---")
    
    col_btn1, col_btn2, col_btn3 = st.columns([1, 1, 2])
    with col_btn1:
        execute_btn = st.button("ğŸš€ å¼€å§‹å¯è§†åŒ–", key="viz_execute_button", use_container_width=True)

    if execute_btn:
        if not uploaded_file or not save_filename:
            st.warning("âš ï¸ è¯·ç¡®ä¿å·²ä¸Šä¼ æ•°æ®æ–‡ä»¶å¹¶è¾“å…¥è¾“å‡ºæ–‡ä»¶å")
            return

        with st.spinner("ğŸ”„ æ­£åœ¨ç”Ÿæˆå¯è§†åŒ–æŠ¥è¡¨ï¼Œè¯·ç¨å€™..."):
            save_path = unique_tmp_path(save_filename)

            try:
                df = _read_excel_cached(uploaded_file, sheet_name='æºæ•°æ®')
                if df.empty:
                    st.warning("ğŸ“‚ ä¸Šä¼ çš„æ–‡ä»¶ä¸ºç©ºæˆ–ä¸åŒ…å«'æºæ•°æ®'å·¥ä½œè¡¨ï¼Œè¯·æ£€æŸ¥æ•°æ®æ–‡ä»¶")
                    return

                # æ·»åŠ å“ç‰Œè¯å¤„ç†è¿›åº¦æ¡
                brand_progress = st.progress(0)
                brand_status = st.empty()
                brand_status.text("æ­£åœ¨å¤„ç†å“ç‰Œè¯...")
                brand_words_list = []
                for index, row in df.iterrows():
                    search_volumn = row['æœç´¢é‡'] if pd.notna(row['æœç´¢é‡']) else 0
                    brand_value = str(row['å“ç‰Œ']) if not pd.isna(row['å“ç‰Œ']) else ''
                    matched_brands = brand_value.split(',') if brand_value else []
                    for brand in matched_brands:
                        if brand:
                            brand_words_list.append({'å“ç‰Œåç§°': brand, 'æœç´¢é‡': search_volumn})
                    if index % max(1, len(df) // 10) == 0 or index == len(df) - 1:
                        brand_progress.progress((index + 1) / len(df))
                brand_words_df = pd.DataFrame(brand_words_list)
                if not brand_words_df.empty:
                    brand_words_df = brand_words_df.groupby('å“ç‰Œåç§°', as_index=False)['æœç´¢é‡'].sum()
                    brand_words_df = aggregate_top_n(brand_words_df, value_col='æœç´¢é‡', name_col='å“ç‰Œåç§°')
                brand_status.text("å“ç‰Œè¯å¤„ç†å®Œæˆ")
                brand_progress.empty()
                brand_status.empty()

                # æ·»åŠ å‚æ•°çƒ­å›¾å¤„ç†è¿›åº¦æ¡
                param_progress = st.progress(0)
                param_status = st.empty()
                param_status.text("æ­£åœ¨å¤„ç†å‚æ•°...")
                param_heats = {}
                param_columns = [col for col in df.columns if col not in ['æœç´¢è¯', 'æœç´¢é‡', 'å“ç‰Œåç§°', 'å“ç‰Œ', 'ç‰¹æ€§å‚æ•°', 'è¯æ€§']]
                for col_idx, column in enumerate(param_columns):
                    param_heats[column] = []
                    for index, row in df.iterrows():
                        search_volumn = row['æœç´¢é‡'] if pd.notna(row['æœç´¢é‡']) else 0
                        param_value = str(row[column]) if not pd.isna(row[column]) else ''
                        matched_values = param_value.split(',') if param_value else []
                        for param in matched_values:
                            if param:
                                param_heats[column].append({'å‚æ•°å€¼': param, 'æœç´¢é‡': search_volumn})
                    param_progress.progress((col_idx + 1) / len(param_columns))
                param_status.text("å‚æ•°å¤„ç†å®Œæˆ")
                param_progress.empty()
                param_status.empty()

                # æ·»åŠ å·¥ä½œç°¿ä¿å­˜è¿›åº¦æ¡
                save_progress = st.progress(0)
                save_status = st.empty()
                save_status.text("æ­£åœ¨ç”ŸæˆExcelå·¥ä½œç°¿...")
                save_progress.progress(0.3)

                workbook = Workbook()
                if "Sheet" in workbook.sheetnames:
                    workbook.remove(workbook["Sheet"])

                ws_source = workbook.create_sheet('æºæ•°æ®')
                for r in dataframe_to_rows(df, index=False, header=True):
                    ws_source.append(r)
                save_progress.progress(0.6)

                if not brand_words_df.empty:
                    ws_brands = workbook.create_sheet('å“ç‰Œè¯æ‹†è§£')
                    for r in dataframe_to_rows(brand_words_df, index=False, header=True):
                        ws_brands.append(r)
                save_progress.progress(0.7)

                for param_idx, (param_name, heats) in enumerate(param_heats.items()):
                    if heats:
                        param_df = pd.DataFrame(heats).groupby('å‚æ•°å€¼', as_index=False)['æœç´¢é‡'].sum()
                        param_df = aggregate_top_n(param_df, value_col='æœç´¢é‡', name_col='å‚æ•°å€¼')
                        clean_sheet_name = param_name[:31].translate(str.maketrans('', '', '\/?*[]'))
                        ws_param = workbook.create_sheet(f"{clean_sheet_name}æ‹†è§£")
                        for r in dataframe_to_rows(param_df, index=False, header=True):
                            ws_param.append(r)
                    if param_idx % max(1, len(param_heats) // 5) == 0 or param_idx == len(param_heats) - 1:
                        save_progress.progress(0.7 + (0.3 * (param_idx + 1) / len(param_heats)))
                save_progress.progress(1.0)

                df_selected = df[['è¯æ€§', 'æœç´¢é‡']].groupby('è¯æ€§').sum().reset_index()
                if not df_selected.empty:
                    df_selected = aggregate_top_n(df_selected, value_col='æœç´¢é‡', name_col='è¯æ€§')
                    ws_traffic = workbook.create_sheet('å“ç±»æµé‡ç»“æ„')
                    for r in dataframe_to_rows(df_selected, index=False, header=True):
                        ws_traffic.append(r)

                timestamp = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')
                output_filename = f"viz_result_{timestamp}.xlsx"
                output_path = os.path.join("/tmp", output_filename)

                buffer = io.BytesIO()
                workbook.save(buffer)
                buffer.seek(0)
                save_status.text("å·¥ä½œç°¿ç”Ÿæˆå®Œæˆ")
                save_progress.empty()
                save_status.empty()

                st.success("âœ… æ•°æ®å¤„ç†å®Œæˆï¼Œæ­£åœ¨ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")

                st.markdown("### ğŸ“Š æ•°æ®å¯è§†åŒ–")

                if not brand_words_df.empty:
                    with st.container():
                        pie_chart(brand_words_df, 'æœç´¢é‡', 'å“ç‰Œåç§°', "å“ç‰Œè¯æ‹†è§£")

                for param_name, heats in param_heats.items():
                    if heats:
                        param_df = pd.DataFrame(heats).groupby('å‚æ•°å€¼', as_index=False)['æœç´¢é‡'].sum()
                        param_df = aggregate_top_n(param_df, value_col='æœç´¢é‡', name_col='å‚æ•°å€¼')
                        with st.container():
                            pie_chart(param_df, 'æœç´¢é‡', 'å‚æ•°å€¼', f"{param_name} å‚æ•°æœç´¢é‡åˆ†å¸ƒ")

                if not df_selected.empty:
                    with st.container():
                        pie_chart(df_selected, 'æœç´¢é‡', 'è¯æ€§', "æµé‡ç»“æ„")

                st.markdown("---")
                
                col_download, col_save = st.columns(2)
                with col_download:
                    st.download_button(
                        label="ğŸ“¥ ä¸‹è½½å®Œæ•´æŠ¥è¡¨",
                        data=buffer,
                        file_name=output_filename,
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                        key="viz_download_result",
                        use_container_width=True
                    )
                with col_save:
                    if st.checkbox("ğŸ’¾ åŒæ—¶ä¿å­˜åˆ° /tmp ç›®å½•", key="viz_save_result"):
                        workbook.save(output_path)
                        st.info(f"ğŸ“ æ–‡ä»¶å·²ä¿å­˜åˆ° {output_path}")

            except Exception as e:
                st.error(f"âŒ å¤„ç†æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯:{e}")

# æ–°åŠŸèƒ½:åˆ é™¤ç¬¬ä¸€è¡Œå¹¶é‡æ–°æ‰“åŒ…ZIP
def data_clean_app():
    st.markdown("""
    <div style="background: linear-gradient(135deg, #00a6e4 0%, #0088c2 100%); padding: 2rem; border-radius: 10px; margin-bottom: 2rem; box-shadow: 0 4px 6px rgba(0,0,0,0.1);">
        <h2 style="color: white; margin: 0; display: flex; align-items: center;">
            ğŸ§¹ DC - æ•°æ®æ¸…ç†: åˆ é™¤ç¬¬ä¸€è¡Œ
        </h2>
        <p style="color: rgba(255,255,255,0.9); margin-top: 0.5rem;">æ‰¹é‡åˆ é™¤Excel/CSVæ–‡ä»¶çš„ç¬¬ä¸€è¡Œæ•°æ®å¹¶é‡æ–°æ‰“åŒ…</p>
    </div>
    """, unsafe_allow_html=True)
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown("#### ğŸ“ ä¸Šä¼ æ–‡ä»¶")
        uploaded_file = st.file_uploader(
            "é€‰æ‹©ä¸€ä¸ª .zip æ–‡ä»¶(åŒ…å« XLSX æˆ– CSV æ–‡ä»¶)", 
            type=["zip"], 
            accept_multiple_files=False, 
            key="clean_files",
            help="æ”¯æŒåŒ…å«.xlsxã€.xlsã€.csvæ ¼å¼çš„ZIPå‹ç¼©åŒ…"
        )
    
    with col2:
        st.markdown("#### ğŸ’¾ è¾“å‡ºè®¾ç½®")
        output_filename = st.text_input(
            "è¾“å‡ºæ–‡ä»¶å", 
            value="cleaned_files.zip", 
            key="clean_save",
            help="è¯·è¾“å…¥è¾“å‡ºZIPæ–‡ä»¶å"
        )
    
    st.markdown("---")
    
    col_btn1, col_btn2, col_btn3 = st.columns([1, 1, 2])
    with col_btn1:
        execute_btn = st.button("ğŸš€ å¼€å§‹æ¸…ç†", key="clean_button", use_container_width=True)
    
    if execute_btn:
        if not uploaded_file or not output_filename:
            st.warning("âš ï¸ è¯·ç¡®ä¿å·²é€‰æ‹© .zip æ–‡ä»¶å¹¶è¾“å…¥è¾“å‡ºæ–‡ä»¶å")
            return
        
        with st.spinner("ğŸ”„ æ­£åœ¨æ¸…ç†æ–‡ä»¶ï¼Œè¯·ç¨å€™..."):
            try:
                with tempfile.TemporaryDirectory() as temp_dir:
                    temp_zip_path = os.path.join(temp_dir, uploaded_file.name)
                    with open(temp_zip_path, "wb") as f:
                        f.write(uploaded_file.getbuffer())
                    
                    with zipfile.ZipFile(temp_zip_path, 'r') as zip_ref:
                        zip_ref.extractall(temp_dir)
                    
                    data_files = [f for f in os.listdir(temp_dir) if f.endswith(('.xlsx', '.xls', '.csv'))]
                    
                    if not data_files:
                        st.warning("ğŸ“‚ å‹ç¼©æ–‡ä»¶ä¸­æœªæ‰¾åˆ°ä»»ä½• XLSXã€XLS æˆ– CSV æ–‡ä»¶")
                        return
                    
                    processed_files = []
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    
                    for idx, file_name in enumerate(data_files):
                        file_path = os.path.join(temp_dir, file_name)
                        try:
                            status_text.text(f"æ­£åœ¨å¤„ç†: {file_name} ({idx+1}/{len(data_files)})")
                            
                            if file_name.endswith(('.xlsx', '.xls')):
                                df = pd.read_excel(file_path, engine='openpyxl' if file_name.endswith('.xlsx') else 'xlrd')
                            elif file_name.endswith('.csv'):
                                df = pd.read_csv(file_path, header=None)
                            
                            df = df.iloc[1:].reset_index(drop=True)
                            
                            processed_path = os.path.join(temp_dir, f"cleaned_{file_name}")
                            if file_name.endswith(('.xlsx', '.xls')):
                                df.to_excel(processed_path, index=False, engine='openpyxl')
                            elif file_name.endswith('.csv'):
                                df.to_csv(processed_path, index=False)
                            
                            processed_files.append(processed_path)
                            progress_bar.progress((idx + 1) / len(data_files))
                        except Exception as e:
                            st.error(f"âŒ å¤„ç†æ–‡ä»¶ {file_name} å¤±è´¥:{e}")
                            continue
                    
                    status_text.empty()
                    progress_bar.empty()
                    
                    if processed_files:
                        # æ·»åŠ æ‰“åŒ…è¿›åº¦æ¡
                        zip_progress = st.progress(0)
                        zip_status = st.empty()
                        zip_status.text("æ­£åœ¨æ‰“åŒ…ZIPæ–‡ä»¶...")
                        buffer = io.BytesIO()
                        with zipfile.ZipFile(buffer, 'w', zipfile.ZIP_DEFLATED) as new_zip:
                            for proc_idx, proc_path in enumerate(processed_files):
                                arcname = os.path.basename(proc_path).replace("cleaned_", "")
                                new_zip.write(proc_path, arcname=arcname)
                                zip_progress.progress((proc_idx + 1) / len(processed_files))
                        buffer.seek(0)
                        zip_status.text("æ‰“åŒ…å®Œæˆ")
                        zip_progress.empty()
                        zip_status.empty()
                        
                        st.success(f"âœ… æˆåŠŸæ¸…ç† {len(processed_files)} ä¸ªæ–‡ä»¶")
                        
                        st.download_button(
                            label="ğŸ“¥ ä¸‹è½½æ¸…ç†åçš„ ZIP æ–‡ä»¶",
                            data=buffer,
                            file_name=output_filename,
                            mime="application/zip",
                            key="download_cleaned",
                            use_container_width=True
                        )
                    else:
                        st.warning("âš ï¸ æ²¡æœ‰å¯æ¸…ç†çš„æ–‡ä»¶")
            except Exception as e:
                st.error(f"âŒ å¤„ç† ZIP æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯:{e}")

# ä¸»åº”ç”¨ç¨‹åº
def main():
    st.set_page_config(
        page_title=APP_CONFIG["app_title"], 
        layout="wide",
        page_icon="ğŸ“Š",
        initial_sidebar_state="collapsed"
    )
    
    # è‡ªå®šä¹‰CSSä¼˜åŒ–UI,ä¸»è‰²è°ƒ #00a6e4
    st.markdown("""
    <style>
        /* å…¨å±€å­—ä½“å’ŒèƒŒæ™¯ */
        @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap');
        
        html, body, [class*="css"] {
            font-family: 'Inter', 'Segoe UI', sans-serif;
        }
        
        .main {
            background: linear-gradient(135deg, #f5f7fa 0%, #e9ecef 100%);
        }
        
        /* æ ‡é¢˜é¢œè‰² */
        h1, h2, h3, h4, h5, h6 {
            color: #ffffff !important;
            font-weight: 600 !important;
        }
        
        /* æŒ‰é’®æ ·å¼ */
        .stButton > button {
            background: linear-gradient(135deg, #00a6e4 0%, #0088c2 100%);
            color: white;
            border: none;
            border-radius: 8px;
            padding: 0.6rem 1.5rem;
            font-weight: 600;
            font-size: 15px;
            transition: all 0.3s ease;
            box-shadow: 0 4px 6px rgba(0, 166, 228, 0.2);
        }
        
        .stButton > button:hover {
            background: linear-gradient(135deg, #0088c2 0%, #006a99 100%);
            box-shadow: 0 6px 12px rgba(0, 166, 228, 0.3);
            transform: translateY(-2px);
        }
        
        /* ä¸‹è½½æŒ‰é’®æ ·å¼ */
        .stDownloadButton > button {
            background: linear-gradient(135deg, #00a6e4 0%, #0088c2 100%);
            color: white;
            border: none;
            border-radius: 8px;
            padding: 0.6rem 1.5rem;
            font-weight: 600;
            font-size: 15px;
            transition: all 0.3s ease;
            box-shadow: 0 4px 6px rgba(0, 166, 228, 0.2);
        }
        
        .stDownloadButton > button:hover {
            background: linear-gradient(135deg, #0088c2 0%, #006a99 100%);
            box-shadow: 0 6px 12px rgba(0, 166, 228, 0.3);
            transform: translateY(-2px);
        }
        
        /* æ–‡ä»¶ä¸Šä¼ å™¨æ ·å¼ */
        .stFileUploader {
            background: white;
            border-radius: 10px;
            padding: 1.5rem;
            box-shadow: 0 2px 8px rgba(0,0,0,0.08);
        }
        
        [data-testid="stFileUploadDropzone"] {
            border: 2px dashed #00a6e4;
            border-radius: 8px;
            background: #f8fcff;
        }
        
        /* è¾“å…¥æ¡†æ ·å¼ */
        .stTextInput > div > div > input,
        .stTextArea > div > div > textarea {
            border: 2px solid #e0e0e0;
            border-radius: 8px;
            padding: 0.6rem;
            transition: all 0.3s ease;
            font-size: 14px;
        }
        
        .stTextInput > div > div > input:focus,
        .stTextArea > div > div > textarea:focus {
            border-color: #00a6e4;
            box-shadow: 0 0 0 3px rgba(0, 166, 228, 0.1);
        }
        
        /* è¿›åº¦æ¡æ ·å¼ */
        .stProgress > div > div > div > div {
            background: linear-gradient(90deg, #00a6e4 0%, #0088c2 100%);
        }
        
        /* æˆåŠŸ/é”™è¯¯/è­¦å‘Šæ¶ˆæ¯æ ·å¼ */
        .stSuccess {
            background: linear-gradient(135deg, #d4edda 0%, #c3e6cb 100%);
            border-left: 4px solid #28a745;
            border-radius: 8px;
            padding: 1rem;
        }
        
        .stError {
            background: linear-gradient(135deg, #f8d7da 0%, #f5c6cb 100%);
            border-left: 4px solid #dc3545;
            border-radius: 8px;
            padding: 1rem;
        }
        
        .stWarning {
            background: linear-gradient(135deg, #fff3cd 0%, #ffeaa7 100%);
            border-left: 4px solid #ffc107;
            border-radius: 8px;
            padding: 1rem;
        }
        
        .stInfo {
            background: linear-gradient(135deg, #d1ecf1 0%, #bee5eb 100%);
            border-left: 4px solid #00a6e4;
            border-radius: 8px;
            padding: 1rem;
        }
        
        /* å¤é€‰æ¡†æ ·å¼ */
        .stCheckbox {
            font-size: 14px;
        }
        
        /* åˆ†éš”çº¿æ ·å¼ */
        hr {
            margin: 2rem 0;
            border: none;
            border-top: 2px solid #e0e0e0;
        }
        
        /* å¡ç‰‡æ•ˆæœ */
        div[data-testid="column"] {
            background: white;
            padding: 1rem;
            border-radius: 10px;
            box-shadow: 0 2px 8px rgba(0,0,0,0.05);
        }
        
        /* Plotlyå›¾è¡¨å®¹å™¨ */
        .js-plotly-plot {
            border-radius: 10px;
            box-shadow: 0 4px 12px rgba(0,0,0,0.1);
        }
    </style>
    """, unsafe_allow_html=True)
    
    # é¡µé¢å¤´éƒ¨
    st.markdown("""
    <div style="background: linear-gradient(135deg, #00a6e4 0%, #0088c2 100%); padding: 2.5rem 2rem; border-radius: 15px; margin-bottom: 2rem; box-shadow: 0 8px 16px rgba(0,0,0,0.15);">
        <h1 style="color: white; margin: 0; font-size: 2.5rem; font-weight: 700;">
            ğŸ“Š å¸‚åœºæ´å¯Ÿå°ç¨‹åº
        </h1>
        <div style="display: flex; gap: 2rem; margin-top: 1rem; flex-wrap: wrap;">
            <span style="color: rgba(255,255,255,0.95); font-size: 14px;">
                <strong>ç‰ˆæœ¬:</strong> v1.2.0
            </span>
            <span style="color: rgba(255,255,255,0.95); font-size: 14px;">
                <strong>ä½œè€…:</strong> æµ·ç¿¼IDCå›¢é˜Ÿ
            </span>
            <span style="color: rgba(255,255,255,0.95); font-size: 14px;">
                <strong>å…¬å¸:</strong> Anker Oceanwing Inc.
            </span>
            <span style="color: rgba(255,255,255,0.95); font-size: 14px;">
                <strong>è”ç³»:</strong> idc@oceanwing.com
            </span>
        </div>
    </div>
    """, unsafe_allow_html=True)
    
    # åŠŸèƒ½å¯¼èˆª
    st.markdown("""
    <div style="background: white; padding: 1.5rem; border-radius: 10px; margin-bottom: 2rem; box-shadow: 0 2px 8px rgba(0,0,0,0.08);">
        <h3 style="margin-top: 0; color: #333;">ğŸ¯ åŠŸèƒ½å¯¼èˆª</h3>
        <p style="color: #666; margin-bottom: 0;">é€‰æ‹©ä¸‹æ–¹åŠŸèƒ½æ¨¡å—å¼€å§‹æ‚¨çš„æ•°æ®åˆ†æä¹‹æ—…</p>
    </div>
    """, unsafe_allow_html=True)
    
    # åŠŸèƒ½æ¨¡å—
    tabs = st.tabs([
        "ğŸ“Š åˆå¹¶æ•°æ®è¡¨æ ¼",
        "ğŸ” æœç´¢æµé‡æ´å¯Ÿ",
        "ğŸ“ˆ æµé‡å¯è§†åŒ–åˆ†æ",
        "ğŸ§¹ æ•°æ®æ¸…ç†å·¥å…·"
    ])
    
    with tabs[0]:
        merge_data_app()
    
    with tabs[1]:
        search_insight_app()
    
    with tabs[2]:
        search_insight_viz_app()
    
    with tabs[3]:
        data_clean_app()
    
    # é¡µè„š
    st.markdown("---")
    st.markdown("""
    <div style="text-align: center; color: #666; padding: 2rem 0;">
        <p style="margin: 0;">Â© Anker Oceanwing Inc. | æµ·ç¿¼IDCå›¢é˜Ÿ</p>
        <p style="margin: 0.5rem 0 0 0; font-size: 13px;">å¸‚åœºæ´å¯Ÿå°ç¨‹åº v1.2.0 - è®©æ•°æ®åˆ†ææ›´ç®€å•</p>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()
