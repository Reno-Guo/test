import streamlit as st
import pandas as pd
import os
from datetime import datetime
import io
import zipfile
import tempfile
import calendar

def save_df_to_buffer(df: pd.DataFrame) -> io.BytesIO:
    buffer = io.BytesIO()
    df.to_excel(buffer, index=False, engine="openpyxl")
    buffer.seek(0)
    return buffer

def render_app_header(emoji_title: str, subtitle: str):
    st.markdown(f"""
    <div style="background: linear-gradient(135deg, #00a6e4 0%, #0088c2 100%); padding: 2rem; border-radius: 10px; margin-bottom: 2rem; box-shadow: 0 4px 6px rgba(0,0,0,0.1);">
        <h2 style="color: white; margin: 0; display: flex; align-items: center;">
            {emoji_title}
        </h2>
        <p style="color: rgba(255,255,255,0.9); margin-top: 0.5rem;">{subtitle}</p>
    </div>
    """, unsafe_allow_html=True)

def csv_to_dataframe(csv_path: str, header_row: int = 0) -> pd.DataFrame:
    encodings = ['utf-8', 'gbk', 'gb2312', 'latin-1', 'cp1252']
    for encoding in encodings:
        try:
            df = pd.read_csv(csv_path, encoding=encoding, header=header_row)
            return df
        except (UnicodeDecodeError, pd.errors.ParserError):
            continue
    df = pd.read_csv(csv_path, encoding='utf-8', header=header_row, encoding_errors='ignore')
    return df

def excel_to_dataframe(excel_path: str, header_row: int = 0) -> pd.DataFrame:
    return pd.read_excel(excel_path, header=header_row)

def process_zip_files_with_preview(uploaded_file, header_row: int, file_type: str):
    if uploaded_file is None:
        return pd.DataFrame()
    
    with tempfile.TemporaryDirectory() as temp_dir:
        zip_path = os.path.join(temp_dir, uploaded_file.name)
        with open(zip_path, "wb") as f:
            f.write(uploaded_file.getbuffer())
        
        with zipfile.ZipFile(zip_path, "r") as z:
            z.extractall(temp_dir)
        
        files = [f for f in os.listdir(temp_dir) if f.lower().endswith(('.csv', '.xlsx', '.xls'))]
        if not files:
            st.warning(f"ðŸ“‚ {file_type}åŽ‹ç¼©åŒ…ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆæ–‡ä»¶")
            return pd.DataFrame()
        
        dfs = []
        for f in files:
            fp = os.path.join(temp_dir, f)
            try:
                if f.lower().endswith('.csv'):
                    df = csv_to_dataframe(fp, header_row=header_row)
                else:
                    df = excel_to_dataframe(fp, header_row=header_row)
                
                with st.expander(f"ðŸ“„ {file_type} - {f} é¢„è§ˆ"):
                    st.write(f"**åˆ—å:** {list(df.columns)}")
                    st.write(f"**å½¢çŠ¶:** {df.shape}")
                    st.dataframe(df.head(3), use_container_width=True)
                dfs.append(df.reset_index(drop=True))
            except Exception as e:
                st.error(f"âŒ å¤„ç† {f} å¤±è´¥: {str(e)[:100]}...")
        
        if not dfs:
            return pd.DataFrame()
        
        result = pd.concat(dfs, ignore_index=True, sort=False)
        return result

def process_zip_files(uploaded_file, header_row: int):
    if uploaded_file is None:
        return pd.DataFrame()
    
    with tempfile.TemporaryDirectory() as temp_dir:
        zip_path = os.path.join(temp_dir, uploaded_file.name)
        with open(zip_path, "wb") as f:
            f.write(uploaded_file.getbuffer())
        
        with zipfile.ZipFile(zip_path, "r") as z:
            z.extractall(temp_dir)
        
        files = [f for f in os.listdir(temp_dir) if f.lower().endswith(('.csv', '.xlsx', '.xls'))]
        if not files:
            return pd.DataFrame()
        
        dfs = []
        for f in files:
            fp = os.path.join(temp_dir, f)
            try:
                if f.lower().endswith('.csv'):
                    df = csv_to_dataframe(fp, header_row=header_row)
                else:
                    df = excel_to_dataframe(fp, header_row=header_row)
                dfs.append(df.reset_index(drop=True))
            except:
                continue
        
        if not dfs:
            return pd.DataFrame()
        
        result = pd.concat(dfs, ignore_index=True, sort=False)
        return result

def parse_month_year_to_yyyy_mm(col_name: str) -> str:
    """å°† 'December 2023' æˆ– 'December-2023' è½¬ä¸º '2023-12'"""
    clean = col_name.replace(',', '').replace('-', ' ').strip()
    parts = clean.split()
    if len(parts) < 2:
        return col_name  # æ— æ³•è§£æžåˆ™åŽŸæ ·è¿”å›ž
    month_name, year_str = parts[0], parts[1]
    try:
        month_num = list(calendar.month_name).index(month_name.capitalize())
        return f"{year_str}-{month_num:02d}"
    except ValueError:
        return col_name  # æ— æ•ˆæœˆä»½ååˆ™åŽŸæ ·è¿”å›ž

def sales_data_merge_app():
    render_app_header("ðŸ”— é”€å”®æ•°æ®åˆå¹¶å·¥å…·", "åˆå¹¶æœˆåº¦æ”¶å…¥ã€å•ä½æ•°æ®ä¸ŽASINè¯¦ç»†ä¿¡æ¯ï¼ˆå«æ ‡å‡†æ—¶é—´æ ¼å¼ï¼‰")
    
    st.markdown("### ðŸ“¥ ä¸Šä¼ æ•°æ®æ–‡ä»¶")
    col1, col2, col3 = st.columns(3)
    with col1:
        rev_zip = st.file_uploader("æœˆåº¦æ”¶å…¥ZIP", type=["zip"], key="rev")
    with col2:
        units_zip = st.file_uploader("æœˆåº¦å•ä½ZIP", type=["zip"], key="units")
    with col3:
        asin_zip = st.file_uploader("ASINè¯¦æƒ…ZIP", type=["zip"], key="asin")
    
    st.divider()
    preview_btn = st.button("ðŸ” é¢„è§ˆå„æ–‡ä»¶å†…å®¹", use_container_width=True)
    execute_btn = st.button("ðŸš€ å¼€å§‹åˆå¹¶æ•°æ®", use_container_width=True)
    
    if preview_btn:
        if not all([rev_zip, units_zip, asin_zip]):
            st.warning("âš ï¸ è¯·å…ˆä¸Šä¼ å…¨éƒ¨ä¸‰ä¸ªæ–‡ä»¶")
            return
        
        with st.spinner("åŠ è½½é¢„è§ˆä¸­..."):
            process_zip_files_with_preview(rev_zip, header_row=1, file_type="æœˆåº¦æ”¶å…¥")
            process_zip_files_with_preview(units_zip, header_row=1, file_type="æœˆåº¦å•ä½")
            process_zip_files_with_preview(asin_zip, header_row=0, file_type="ASINè¯¦æƒ…")
    
    if execute_btn:
        if not all([rev_zip, units_zip, asin_zip]):
            st.warning("âš ï¸ è¯·ä¸Šä¼ æ‰€æœ‰ä¸‰ä¸ªZIPæ–‡ä»¶")
            return
        
        with st.spinner("å¤„ç†æ•°æ®ä¸­..."):
            rev_df = process_zip_files(rev_zip, header_row=1)
            units_df = process_zip_files(units_zip, header_row=1)
            asin_df = process_zip_files(asin_zip, header_row=0)
            
            if rev_df.empty or units_df.empty or asin_df.empty:
                st.error("âŒ æŸä¸ªæ–‡ä»¶åŠ è½½å¤±è´¥")
                return
            
            # æž„å»ºé•¿æ ¼å¼æ•°æ®
            month_cols = [col for col in rev_df.columns if col not in ['Product', 'Product Name', 'Brand', 'Total']]
            
            rev_long_list = []
            for col in month_cols:
                temp = rev_df[['Product', col]].dropna(subset=[col]).copy()
                temp.columns = ['Product', 'Total Revenue']
                time_val = parse_month_year_to_yyyy_mm(col)
                temp['æ—¶é—´'] = time_val
                rev_long_list.append(temp.reset_index(drop=True))
            
            if rev_long_list:
                rev_long_df = pd.concat(rev_long_list, ignore_index=True)
            else:
                rev_long_df = pd.DataFrame(columns=['Product', 'Total Revenue', 'æ—¶é—´'])
            
            units_long_list = []
            for col in month_cols:
                temp = units_df[['Product', col]].dropna(subset=[col]).copy()
                temp.columns = ['Product', 'Unit Sales']
                time_val = parse_month_year_to_yyyy_mm(col)
                temp['æ—¶é—´'] = time_val
                units_long_list.append(temp.reset_index(drop=True))
            
            if units_long_list:
                units_long_df = pd.concat(units_long_list, ignore_index=True)
            else:
                units_long_df = pd.DataFrame(columns=['Product', 'Unit Sales', 'æ—¶é—´'])
            
            # åˆå¹¶æ”¶å…¥å’Œå•ä½æ•°æ®
            if not rev_long_df.empty and not units_long_df.empty:
                combined = rev_long_df.merge(units_long_df, on=['Product', 'æ—¶é—´'], how='inner')
            else:
                st.error("âŒ æ— æœ‰æ•ˆæœˆåº¦æ•°æ®")
                return
            
            # ä¸ŽASINè¯¦æƒ…åˆå¹¶
            final = asin_df.merge(combined, left_on='ASIN', right_on='Product', how='inner')
            
            # === æ¸…ç† _x / _y åˆ— ===
            if 'Total Revenue_x' in final.columns and 'Total Revenue_y' in final.columns:
                final['Total Revenue'] = final['Total Revenue_y']
                final = final.drop(columns=['Total Revenue_x', 'Total Revenue_y'])
            elif 'Total Revenue_y' in final.columns:
                final = final.rename(columns={'Total Revenue_y': 'Total Revenue'})
            elif 'Total Revenue_x' in final.columns:
                final = final.rename(columns={'Total Revenue_x': 'Total Revenue'})

            if 'Unit Sales_x' in final.columns and 'Unit Sales_y' in final.columns:
                final['Unit Sales'] = final['Unit Sales_y']
                final = final.drop(columns=['Unit Sales_x', 'Unit Sales_y'])
            elif 'Unit Sales_y' in final.columns:
                final = final.rename(columns={'Unit Sales_y': 'Unit Sales'})
            elif 'Unit Sales_x' in final.columns:
                final = final.rename(columns={'Unit Sales_x': 'Unit Sales'})

            if 'Product_x' in final.columns and 'Product_y' in final.columns:
                final['Product'] = final['Product_x']
                final = final.drop(columns=['Product_x', 'Product_y'])
            elif 'Product_y' in final.columns:
                final = final.rename(columns={'Product_y': 'Product'})
            elif 'Product_x' in final.columns:
                final = final.rename(columns={'Product_x': 'Product'})

            # === æŒ‰æŒ‡å®šé¡ºåºé‡æŽ’åˆ— ===
            desired_order = [
                'Product', 'ASIN', 'Brand', 'Price', 'BSR', 'Number of sellers', 'Fulfillment',
                'FBA fees (USD)', 'Ratings', 'Review count', 'Images', 'Buy Box', 'Category',
                'Subcategory', 'Size tier', 'Dimensions', 'Weight', 'Creation date', 'Variation count',
                'Net price', 'Sales trend (90 days)', 'Price trend (90 days)', 'Best sales period',
                'Sales to reviews', 'Parent ASIN', 'Price per unit', 'Unit count', 'Pack form',
                'Manufacturer', 'Unit Sales', 'Unit Sales Actuals', 'Total Revenue', 'Total Revenue Actuals', 'æ—¶é—´'
            ]
            
            existing_cols = [col for col in desired_order if col in final.columns]
            extra_cols = [col for col in final.columns if col not in desired_order]
            final = final[existing_cols + extra_cols]
            
            if final.empty:
                st.warning("âš ï¸ æ— åŒ¹é…è®°å½•")
                return
            
            # ä¿å­˜ç»“æžœ
            buffer = save_df_to_buffer(final)
            out_name = f"merged_sales_{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}.xlsx"
            
            st.success(f"âœ… åˆå¹¶å®Œæˆï¼å…± {len(final)} è¡Œæ•°æ®")
            st.dataframe(final.head(10), use_container_width=True)
            
            st.download_button(
                "ðŸ“¥ ä¸‹è½½åˆå¹¶ç»“æžœ",
                data=buffer,
                file_name=out_name,
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                use_container_width=True
            )
