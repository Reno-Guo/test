import streamlit as st
import pandas as pd
import os
from datetime import datetime
import io
import zipfile
import tempfile
from uuid import uuid4

def save_df_to_buffer(df: pd.DataFrame) -> io.BytesIO:
    buffer = io.BytesIO()
    df.to_excel(buffer, index=False, engine="openpyxl")
    buffer.seek(0)
    return buffer

def render_app_header(emoji_title: str, subtitle: str):
    st.markdown(f"""
    <div style="background: linear-gradient(135deg, #00a6e4 0%, #0088c2 100%); padding: 2rem; border-radius: 10px; margin-bottom: 2rem; box-shadow: 0 4px 6px rgba(0,0,0,0.1);">
        <h2 style="color: white; margin: 0; display: flex; align-items: center;">
            {emoji_title}
        </h2>
        <p style="color: rgba(255,255,255,0.9); margin-top: 0.5rem;">{subtitle}</p>
    </div>
    """, unsafe_allow_html=True)

def get_timestamp() -> str:
    return datetime.now().strftime("%Y-%m-%d_%H-%M-%S")

def csv_to_dataframe(csv_path: str, header_row: int = 0) -> pd.DataFrame:
    encodings = ['utf-8', 'gbk', 'gb2312', 'latin-1', 'cp1252']
    for encoding in encodings:
        try:
            df = pd.read_csv(csv_path, encoding=encoding, header=header_row)
            return df
        except (UnicodeDecodeError, pd.errors.ParserError):
            continue
    df = pd.read_csv(csv_path, encoding='utf-8', header=header_row, encoding_errors='ignore')
    return df

def excel_to_dataframe(excel_path: str, header_row: int = 0) -> pd.DataFrame:
    return pd.read_excel(excel_path, header=header_row)

def process_zip_files_with_preview(uploaded_file, header_row: int, file_type: str):
    if uploaded_file is None:
        return pd.DataFrame()
    
    with tempfile.TemporaryDirectory() as temp_dir:
        zip_path = os.path.join(temp_dir, uploaded_file.name)
        with open(zip_path, "wb") as f:
            f.write(uploaded_file.getbuffer())
        
        with zipfile.ZipFile(zip_path, "r") as z:
            z.extractall(temp_dir)
        
        files = [f for f in os.listdir(temp_dir) if f.lower().endswith(('.csv', '.xlsx', '.xls'))]
        if not files:
            st.warning(f"ğŸ“‚ {file_type}å‹ç¼©åŒ…ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆæ–‡ä»¶")
            return pd.DataFrame()
        
        dfs = []
        for f in files:
            fp = os.path.join(temp_dir, f)
            try:
                if f.lower().endswith('.csv'):
                    df = csv_to_dataframe(fp, header_row=header_row)
                else:
                    df = excel_to_dataframe(fp, header_row=header_row)
                
                with st.expander(f"ğŸ“„ {file_type} - {f} é¢„è§ˆ"):
                    st.write(f"**åˆ—å:** {list(df.columns)}")
                    st.write(f"**å½¢çŠ¶:** {df.shape}")
                    st.dataframe(df.head(3), use_container_width=True)
                dfs.append(df)
            except Exception as e:
                st.error(f"âŒ å¤„ç† {f} å¤±è´¥: {str(e)[:100]}...")
        
        if not dfs:
            return pd.DataFrame()
        
        # å®‰å…¨åˆå¹¶ï¼šé‡ç½®ç´¢å¼• + ç»Ÿä¸€åˆ—åç±»å‹
        for i, df in enumerate(dfs):
            df.columns = [str(col).strip() for col in df.columns]  # å¼ºåˆ¶è½¬ä¸ºå­—ç¬¦ä¸²
            dfs[i] = df.reset_index(drop=True)
        
        result = pd.concat(dfs, ignore_index=True, sort=False)
        return result

def sales_data_merge_app():
    render_app_header("ğŸ”— é”€å”®æ•°æ®åˆå¹¶å·¥å…·ï¼ˆä»…ä¿ç•™ä¸‰è¡¨åŒ¹é…é¡¹ï¼‰", "æ”¯æŒæœˆåº¦æ”¶å…¥ã€å•ä½é”€é‡ä¸ASINè¯¦æƒ…å†…è¿æ¥åˆå¹¶")
    
    st.markdown("### ğŸ“¥ ä¸Šä¼ ä¸‰ä¸ªZIPæ•°æ®åŒ…")
    col1, col2, col3 = st.columns(3)
    with col1:
        rev_zip = st.file_uploader("ğŸ“¦ æœˆåº¦æ”¶å…¥ (by month rev.)", type=["zip"], key="rev")
    with col2:
        units_zip = st.file_uploader("ğŸ“¦ æœˆåº¦å•ä½ (by month units)", type=["zip"], key="units")
    with col3:
        asin_zip = st.file_uploader("ğŸ“¦ ASINè¯¦æƒ…æ•°æ®", type=["zip"], key="asin")
    
    st.divider()
    preview_btn = st.button("ğŸ” é¢„è§ˆå„æ–‡ä»¶å†…å®¹", use_container_width=True)
    execute_btn = st.button("ğŸš€ æ‰§è¡Œå†…è¿æ¥åˆå¹¶", use_container_width=True)
    
    if preview_btn:
        if not all([rev_zip, units_zip, asin_zip]):
            st.warning("âš ï¸ è¯·å…ˆä¸Šä¼ å…¨éƒ¨ä¸‰ä¸ªæ–‡ä»¶")
            return
        
        with st.spinner("åŠ è½½é¢„è§ˆä¸­..."):
            rev_df = process_zip_files_with_preview(rev_zip, header_row=1, file_type="æœˆåº¦æ”¶å…¥")
            units_df = process_zip_files_with_preview(units_zip, header_row=1, file_type="æœˆåº¦å•ä½")
            asin_df = process_zip_files_with_preview(asin_zip, header_row=0, file_type="ASINè¯¦æƒ…")
    
    if execute_btn:
        if not all([rev_zip, units_zip, asin_zip]):
            st.warning("âš ï¸ è¯·ä¸Šä¼ å…¨éƒ¨ä¸‰ä¸ªZIPæ–‡ä»¶")
            return
        
        with st.spinner("ğŸ”„ æ­£åœ¨å¤„ç†æ•°æ®..."):
            rev_df = process_zip_files_with_preview(rev_zip, header_row=1, file_type="")
            units_df = process_zip_files_with_preview(units_zip, header_row=1, file_type="")
            asin_df = process_zip_files_with_preview(asin_zip, header_row=0, file_type="")
            
            if rev_df.empty or units_df.empty or asin_df.empty:
                st.error("âŒ æŸä¸ªæ–‡ä»¶æœªèƒ½æ­£ç¡®åŠ è½½")
                return
            
            # åˆ—æ£€æŸ¥
            for name, df, cols in [("æœˆåº¦æ”¶å…¥", rev_df, ['Product']), ("æœˆåº¦å•ä½", units_df, ['Product']), ("ASINè¯¦æƒ…", asin_df, ['ASIN'])]:
                missing = [c for c in cols if c not in df.columns]
                if missing:
                    st.error(f"âŒ {name} ç¼ºå°‘åˆ—: {missing}ã€‚ç°æœ‰åˆ—: {list(df.columns)}")
                    return
            
            # === æ„å»ºé•¿æ ¼å¼æ”¶å…¥æ•°æ® ===
            rev_long_list = []
            skip_cols = {'Product', 'Product Name', 'Brand', 'Total'}
            for col in rev_df.columns:
                if col in skip_cols:
                    continue
                col_str = str(col).strip()
                if not col_str:
                    continue
                temp = rev_df[['Product', col]].dropna(subset=[col]).copy()
                temp.columns = ['Product', 'Total Revenue']
                # è§£ææ—¶é—´
                try:
                    dt = datetime.strptime(col_str, '%B %Y')
                    time_val = dt.strftime('%Y-%m')
                except:
                    try:
                        dt = datetime.strptime(col_str, '%b-%y')
                        time_val = dt.strftime('%Y-%m')
                    except:
                        time_val = col_str
                temp['æ—¶é—´'] = time_val
                rev_long_list.append(temp)
            
            if rev_long_list:
                rev_long_df = pd.concat([
                    df[['Product', 'Total Revenue', 'æ—¶é—´']].reset_index(drop=True)
                    for df in rev_long_list
                ], ignore_index=True)
            else:
                rev_long_df = pd.DataFrame(columns=['Product', 'Total Revenue', 'æ—¶é—´'])
            
            # === æ„å»ºé•¿æ ¼å¼å•ä½æ•°æ® ===
            units_long_list = []
            for col in units_df.columns:
                if col in skip_cols:
                    continue
                col_str = str(col).strip()
                if not col_str:
                    continue
                temp = units_df[['Product', col]].dropna(subset=[col]).copy()
                temp.columns = ['Product', 'Unit Sales']
                try:
                    dt = datetime.strptime(col_str, '%B %Y')
                    time_val = dt.strftime('%Y-%m')
                except:
                    try:
                        dt = datetime.strptime(col_str, '%b-%y')
                        time_val = dt.strftime('%Y-%m')
                    except:
                        time_val = col_str
                temp['æ—¶é—´'] = time_val
                units_long_list.append(temp)
            
            if units_long_list:
                units_long_df = pd.concat([
                    df[['Product', 'Unit Sales', 'æ—¶é—´']].reset_index(drop=True)
                    for df in units_long_list
                ], ignore_index=True)
            else:
                units_long_df = pd.DataFrame(columns=['Product', 'Unit Sales', 'æ—¶é—´'])
            
            # === åˆå¹¶æ”¶å…¥ä¸å•ä½ ===
            if not rev_long_df.empty and not units_long_df.empty:
                combined = rev_long_df.merge(
                    units_long_df,
                    on=['Product', 'æ—¶é—´'],
                    how='inner'
                )
            elif not rev_long_df.empty:
                combined = rev_long_df.copy()
                combined['Unit Sales'] = pd.NA
            elif not units_long_df.empty:
                combined = units_long_df.copy()
                combined['Total Revenue'] = pd.NA
            else:
                st.error("âŒ æ— æœ‰æ•ˆæœˆåº¦æ•°æ®")
                return
            
            # === ä¸ASINè¯¦æƒ…å†…è¿æ¥ ===
            final = asin_df.merge(
                combined,
                left_on='ASIN',
                right_on='Product',
                how='inner'
            )
            
            if final.empty:
                st.warning("âš ï¸ ä¸‰è¡¨æ— å…±åŒåŒ¹é…é¡¹ï¼ˆæ£€æŸ¥ Product ä¸ ASIN æ˜¯å¦å¯¹åº”ï¼‰")
                return
            
            # æ¸…ç†é‡å¤åˆ—
            if 'Product_x' in final.columns and 'Product_y' in final.columns:
                final = final.drop(columns=['Product_y']).rename(columns={'Product_x': 'Product'})
            elif 'Product_y' in final.columns:
                final = final.drop(columns=['Product_y'])
            
            # è¾“å‡ºç»“æœ
            buffer = save_df_to_buffer(final)
            out_name = f"merged_sales_{get_timestamp()}.xlsx"
            out_path = f"/tmp/{out_name}"
            final.to_excel(out_path, index=False)
            
            st.success(f"âœ… åˆå¹¶æˆåŠŸï¼å…± {len(final)} è¡ŒåŒ¹é…è®°å½•")
            st.markdown("### ğŸ“Š ç»“æœé¢„è§ˆ")
            st.dataframe(final.head(10), use_container_width=True)
            
            st.download_button(
                "ğŸ“¥ ä¸‹è½½åˆå¹¶ç»“æœ",
                data=buffer,
                file_name=out_name,
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                use_container_width=True
            )
