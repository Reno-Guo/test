import streamlit as st
import pandas as pd
import os
from datetime import datetime
import io
import zipfile
import tempfile

def save_df_to_buffer(df: pd.DataFrame) -> io.BytesIO:
    buffer = io.BytesIO()
    df.to_excel(buffer, index=False, engine="openpyxl")
    buffer.seek(0)
    return buffer

def render_app_header(emoji_title: str, subtitle: str):
    st.markdown(f"""
    <div style="background: linear-gradient(135deg, #00a6e4 0%, #0088c2 100%); padding: 2rem; border-radius: 10px; margin-bottom: 2rem; box-shadow: 0 4px 6px rgba(0,0,0,0.1);">
        <h2 style="color: white; margin: 0; display: flex; align-items: center;">
            {emoji_title}
        </h2>
        <p style="color: rgba(255,255,255,0.9); margin-top: 0.5rem;">{subtitle}</p>
    </div>
    """, unsafe_allow_html=True)

def csv_to_dataframe(csv_path: str, header_row: int = 0) -> pd.DataFrame:
    encodings = ['utf-8', 'gbk', 'gb2312', 'latin-1', 'cp1252']
    for encoding in encodings:
        try:
            df = pd.read_csv(csv_path, encoding=encoding, header=header_row)
            return df
        except (UnicodeDecodeError, pd.errors.ParserError):
            continue
    df = pd.read_csv(csv_path, encoding='utf-8', header=header_row, encoding_errors='ignore')
    return df

def excel_to_dataframe(excel_path: str, header_row: int = 0) -> pd.DataFrame:
    return pd.read_excel(excel_path, header=header_row)

def process_zip_files_with_preview(uploaded_file, header_row: int, file_type: str):
    if uploaded_file is None:
        return pd.DataFrame()
    
    with tempfile.TemporaryDirectory() as temp_dir:
        zip_path = os.path.join(temp_dir, uploaded_file.name)
        with open(zip_path, "wb") as f:
            f.write(uploaded_file.getbuffer())
        
        with zipfile.ZipFile(zip_path, "r") as z:
            z.extractall(temp_dir)
        
        files = [f for f in os.listdir(temp_dir) if f.lower().endswith(('.csv', '.xlsx', '.xls'))]
        if not files:
            st.warning(f"ğŸ“‚ {file_type}å‹ç¼©åŒ…ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆæ–‡ä»¶")
            return pd.DataFrame()
        
        dfs = []
        for f in files:
            fp = os.path.join(temp_dir, f)
            try:
                if f.lower().endswith('.csv'):
                    df = csv_to_dataframe(fp, header_row=header_row)
                else:
                    df = excel_to_dataframe(fp, header_row=header_row)
                
                with st.expander(f"ğŸ“„ {file_type} - {f} é¢„è§ˆ"):
                    st.write(f"**åˆ—å:** {list(df.columns)}")
                    st.write(f"**å½¢çŠ¶:** {df.shape}")
                    st.dataframe(df.head(3), use_container_width=True)
                dfs.append(df.reset_index(drop=True))
            except Exception as e:
                st.error(f"âŒ å¤„ç† {f} å¤±è´¥: {str(e)[:100]}...")
        
        if not dfs:
            return pd.DataFrame()
        
        result = pd.concat(dfs, ignore_index=True, sort=False)
        return result

def process_zip_files(uploaded_file, header_row: int):
    if uploaded_file is None:
        return pd.DataFrame()
    
    with tempfile.TemporaryDirectory() as temp_dir:
        zip_path = os.path.join(temp_dir, uploaded_file.name)
        with open(zip_path, "wb") as f:
            f.write(uploaded_file.getbuffer())
        
        with zipfile.ZipFile(zip_path, "r") as z:
            z.extractall(temp_dir)
        
        files = [f for f in os.listdir(temp_dir) if f.lower().endswith(('.csv', '.xlsx', '.xls'))]
        if not files:
            return pd.DataFrame()
        
        dfs = []
        for f in files:
            fp = os.path.join(temp_dir, f)
            try:
                if f.lower().endswith('.csv'):
                    df = csv_to_dataframe(fp, header_row=header_row)
                else:
                    df = excel_to_dataframe(fp, header_row=header_row)
                dfs.append(df.reset_index(drop=True))
            except:
                continue
        
        if not dfs:
            return pd.DataFrame()
        
        result = pd.concat(dfs, ignore_index=True, sort=False)
        return result

def sales_data_merge_app():
    render_app_header("ğŸ”— é”€å”®æ•°æ®åˆå¹¶å·¥å…·", "åˆå¹¶æœˆåº¦æ”¶å…¥ã€å•ä½æ•°æ®ä¸ASINè¯¦ç»†ä¿¡æ¯ï¼ˆåˆ—é¡ºåºä¼˜åŒ–ï¼‰")
    
    st.markdown("### ğŸ“¥ ä¸Šä¼ æ•°æ®æ–‡ä»¶")
    col1, col2, col3 = st.columns(3)
    with col1:
        rev_zip = st.file_uploader("æœˆåº¦æ”¶å…¥ZIP", type=["zip"], key="rev")
    with col2:
        units_zip = st.file_uploader("æœˆåº¦å•ä½ZIP", type=["zip"], key="units")
    with col3:
        asin_zip = st.file_uploader("ASINè¯¦æƒ…ZIP", type=["zip"], key="asin")
    
    st.divider()
    preview_btn = st.button("ğŸ” é¢„è§ˆå„æ–‡ä»¶å†…å®¹", use_container_width=True)
    execute_btn = st.button("ğŸš€ å¼€å§‹åˆå¹¶æ•°æ®", use_container_width=True)
    
    if preview_btn:
        if not all([rev_zip, units_zip, asin_zip]):
            st.warning("âš ï¸ è¯·å…ˆä¸Šä¼ å…¨éƒ¨ä¸‰ä¸ªæ–‡ä»¶")
            return
        
        with st.spinner("åŠ è½½é¢„è§ˆä¸­..."):
            process_zip_files_with_preview(rev_zip, header_row=1, file_type="æœˆåº¦æ”¶å…¥")
            process_zip_files_with_preview(units_zip, header_row=1, file_type="æœˆåº¦å•ä½")
            process_zip_files_with_preview(asin_zip, header_row=0, file_type="ASINè¯¦æƒ…")
    
    if execute_btn:
        if not all([rev_zip, units_zip, asin_zip]):
            st.warning("âš ï¸ è¯·ä¸Šä¼ æ‰€æœ‰ä¸‰ä¸ªZIPæ–‡ä»¶")
            return
        
        with st.spinner("å¤„ç†æ•°æ®ä¸­..."):
            rev_df = process_zip_files(rev_zip, header_row=1)
            units_df = process_zip_files(units_zip, header_row=1)
            asin_df = process_zip_files(asin_zip, header_row=0)
            
            if rev_df.empty or units_df.empty or asin_df.empty:
                st.error("âŒ æŸä¸ªæ–‡ä»¶åŠ è½½å¤±è´¥")
                return
            
            # æ„å»ºé•¿æ ¼å¼æ•°æ®
            month_cols = [col for col in rev_df.columns if col not in ['Product', 'Product Name', 'Brand', 'Total']]
            
            rev_long_list = []
            for col in month_cols:
                temp = rev_df[['Product', col]].dropna(subset=[col]).copy()
                temp.columns = ['Product', 'Total Revenue']
                time_val = col.replace(' ', '-').replace(',', '')
                temp['æ—¶é—´'] = time_val
                rev_long_list.append(temp.reset_index(drop=True))
            
            if rev_long_list:
                rev_long_df = pd.concat(rev_long_list, ignore_index=True)
            else:
                rev_long_df = pd.DataFrame(columns=['Product', 'Total Revenue', 'æ—¶é—´'])
            
            units_long_list = []
            for col in month_cols:
                temp = units_df[['Product', col]].dropna(subset=[col]).copy()
                temp.columns = ['Product', 'Unit Sales']
                time_val = col.replace(' ', '-').replace(',', '')
                temp['æ—¶é—´'] = time_val
                units_long_list.append(temp.reset_index(drop=True))
            
            if units_long_list:
                units_long_df = pd.concat(units_long_list, ignore_index=True)
            else:
                units_long_df = pd.DataFrame(columns=['Product', 'Unit Sales', 'æ—¶é—´'])
            
            # åˆå¹¶æ”¶å…¥å’Œå•ä½æ•°æ®
            if not rev_long_df.empty and not units_long_df.empty:
                combined = rev_long_df.merge(units_long_df, on=['Product', 'æ—¶é—´'], how='inner')
            else:
                st.error("âŒ æ— æœ‰æ•ˆæœˆåº¦æ•°æ®")
                return
            
            # ä¸ASINè¯¦æƒ…åˆå¹¶ï¼Œä½¿ç”¨ASINå’ŒProductå…³è”
            final = asin_df.merge(combined, left_on='ASIN', right_on='Product', how='inner')
            
            # é‡æ–°æ’åˆ—åˆ—é¡ºåºï¼šå…ˆASINè¯¦æƒ…åˆ—ï¼Œç„¶åæ–°å¢çš„åˆ—
            original_asin_cols = [col for col in asin_df.columns if col != 'Product']
            new_cols = [col for col in final.columns if col not in original_asin_cols and col != 'Product_y']
            
            # ä¿ç•™ASINè¯¦æƒ…çš„åˆ—é¡ºåºï¼Œç„¶ååŠ ä¸Šæ–°åˆ—
            ordered_cols = ['Product'] + original_asin_cols + new_cols
            # å»é™¤é‡å¤åˆ—å
            ordered_cols = list(dict.fromkeys(ordered_cols))
            
            # ç¡®ä¿æ‰€æœ‰åˆ—éƒ½åœ¨æœ€ç»ˆåˆ—è¡¨ä¸­
            all_cols = set(final.columns)
            for col in all_cols:
                if col not in ordered_cols:
                    ordered_cols.append(col)
            
            final = final[ordered_cols]
            
            # å¤„ç†åˆ—åå†²çªï¼šå°†_x/_yåˆ—åˆå¹¶ä¸ºå•ä¸€åˆ—
            # å¦‚æœå­˜åœ¨Total Revenue_xå’ŒTotal Revenue_yï¼Œä¿ç•™_yåˆ—ä½œä¸ºæ–°çš„Total Revenue
            if 'Total Revenue_x' in final.columns and 'Total Revenue_y' in final.columns:
                # ä¼˜å…ˆä½¿ç”¨_yåˆ—ï¼ˆæ¥è‡ªåˆå¹¶æ•°æ®çš„å€¼ï¼‰
                final['Total Revenue'] = final['Total Revenue_y']
                final = final.drop(columns=['Total Revenue_x', 'Total Revenue_y'])
            
            # å¦‚æœå­˜åœ¨Unit Sales_xå’ŒUnit Sales_yï¼Œä¿ç•™_yåˆ—ä½œä¸ºæ–°çš„Unit Sales
            if 'Unit Sales_x' in final.columns and 'Unit Sales_y' in final.columns:
                # ä¼˜å…ˆä½¿ç”¨_yåˆ—ï¼ˆæ¥è‡ªåˆå¹¶æ•°æ®çš„å€¼ï¼‰
                final['Unit Sales'] = final['Unit Sales_y']
                final = final.drop(columns=['Unit Sales_x', 'Unit Sales_y'])
            
            # å¤„ç†Productåˆ—å†²çª
            if 'Product_x' in final.columns and 'Product_y' in final.columns:
                # ä¿ç•™_xåˆ—ï¼ˆæ¥è‡ªASINè¯¦æƒ…çš„Productï¼‰
                final['Product'] = final['Product_x']
                final = final.drop(columns=['Product_x', 'Product_y'])
            elif 'Product_y' in final.columns:
                # å¦‚æœåªæœ‰Product_yï¼Œä½¿ç”¨å®ƒ
                final['Product'] = final['Product_y']
                final = final.drop(columns=['Product_y'])
            
            if final.empty:
                st.warning("âš ï¸ æ— åŒ¹é…è®°å½•")
                return
            
            # ä¿å­˜ç»“æœ
            buffer = save_df_to_buffer(final)
            out_name = f"merged_sales_{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}.xlsx"
            
            st.success(f"âœ… åˆå¹¶å®Œæˆï¼å…± {len(final)} è¡Œæ•°æ®")
            st.dataframe(final.head(10), use_container_width=True)
            
            st.download_button(
                "ğŸ“¥ ä¸‹è½½åˆå¹¶ç»“æœ",
                data=buffer,
                file_name=out_name,
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                use_container_width=True
            )
