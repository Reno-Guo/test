# search_insight_viz.py
import streamlit as st
import pandas as pd
import re
import plotly.express as px
import os  # Added this import
from utils import render_app_header, unique_tmp_path, _read_excel_cached, save_workbook_to_buffer, render_download_section, get_timestamp, Workbook, dataframe_to_rows

def aggregate_top_n(df, value_col, name_col, top_n=10):
    df = df.copy()
    df[name_col] = df[name_col].astype(str)
    df = df.sort_values(by=value_col, ascending=False).reset_index(drop=True)
    if len(df) > top_n:
        top_df = df.iloc[:top_n]
        others = df.iloc[top_n:][value_col].sum()
        others_row = pd.DataFrame([{name_col: "Others", value_col: others}])
        df = pd.concat([top_df[[name_col, value_col]], others_row], ignore_index=True)
    return df[[name_col, value_col]]

def pie_chart(df, value_col, name_col, title):
    df = df.copy()
    df[name_col] = df[name_col].astype(str)
    df = df.sort_values(by=value_col, ascending=False).reset_index(drop=True)
    if "Others" in df[name_col].values:
        order = [n for n in df[name_col] if n != "Others"] + ["Others"]
        df[name_col] = pd.Categorical(df[name_col], categories=order, ordered=True)
    palette = [
        "#4C8EDA", "#FFA14E", "#F25C5C", "#6BD0C1", "#58C27D", "#F7C948",
        "#B685D6", "#FF90B3", "#BC8D6E", "#C9C9C9", "#81D3EB",
    ]
    fig = px.pie(
        df,
        values=value_col,
        names=name_col,
        title=title,
        color_discrete_sequence=palette,
    )
    fig.update_traces(textinfo="label+percent", sort=False)
    fig.update_layout(
        height=900,
        legend=dict(orientation="v", x=0.8, y=0.5, font=dict(size=16)),
        margin=dict(l=20, r=150, t=50, b=50),
        font=dict(size=16),
    )
    st.plotly_chart(fig, use_container_width=True)

def search_insight_viz_app():
    render_app_header("ğŸ“ˆ SI - æœç´¢æµé‡æ´å¯Ÿ: èšåˆå’Œå¯è§†åŒ–", "ç”Ÿæˆå¤šç»´åº¦æ•°æ®åˆ†ææŠ¥è¡¨å’Œå¯è§†åŒ–å›¾è¡¨")
    col1, col2 = st.columns([2, 1])
    with col1:
        uploaded_file = st.file_uploader(
            "é€‰æ‹©åŒ…å«æºæ•°æ®çš„ Excel æ–‡ä»¶(å®Œæˆæ£€æŸ¥ç¡®è®¤æ— è¯¯)",
            type=["xlsx", "xls"],
            key="viz_data_file",
        )
    with col2:
        save_filename = st.text_input("è¾“å‡ºæ–‡ä»¶å", "viz_result.xlsx", key="viz_save_folder")
    st.divider()
    execute_btn = st.button("ğŸš€ å¼€å§‹å¯è§†åŒ–", key="viz_execute_button", use_container_width=True)
    if execute_btn:
        if not uploaded_file or not save_filename:
            st.warning("âš ï¸ è¯·ç¡®ä¿å·²ä¸Šä¼ æ•°æ®æ–‡ä»¶å¹¶è¾“å…¥è¾“å‡ºæ–‡ä»¶å")
            return
        with st.spinner("ğŸ”„ æ­£åœ¨ç”Ÿæˆå¯è§†åŒ–æŠ¥è¡¨ï¼Œè¯·ç¨å€™..."):
            save_path = unique_tmp_path(save_filename)
            df = _read_excel_cached(uploaded_file, sheet_name="æºæ•°æ®")
            if df.empty:
                st.warning("ğŸ“‚ ä¸Šä¼ çš„æ–‡ä»¶ä¸ºç©ºæˆ–ä¸åŒ…å«'æºæ•°æ®'å·¥ä½œè¡¨ï¼Œè¯·æ£€æŸ¥æ•°æ®æ–‡ä»¶")
                return
            # Brand aggregation
            brand_words = []
            b_status = st.empty()
            b_prog = st.progress(0)
            b_status.text("æ­£åœ¨å¤„ç†å“ç‰Œè¯...")
            step = max(1, len(df) // 10)
            for idx, row in df.iterrows():
                vol = row["æœç´¢é‡"] if pd.notna(row["æœç´¢é‡"]) else 0
                brands = [b.strip() for b in str(row["å“ç‰Œ"]).split(",") if b.strip()]
                for b in brands:
                    brand_words.append({"å“ç‰Œåç§°": b, "æœç´¢é‡": vol})
                if (idx + 1) % step == 0 or idx == len(df) - 1:
                    b_prog.progress((idx + 1) / len(df))
            brand_df = pd.DataFrame()
            if brand_words:
                brand_df = pd.DataFrame(brand_words).groupby("å“ç‰Œåç§°", as_index=False)["æœç´¢é‡"].sum()
                brand_df = aggregate_top_n(brand_df, "æœç´¢é‡", "å“ç‰Œåç§°")
            b_status.text("å“ç‰Œè¯å¤„ç†å®Œæˆ")
            b_prog.empty()
            b_status.empty()
            # Param aggregation (single pass)
            excluded = {"æœç´¢è¯", "æœç´¢é‡", "å“ç‰Œåç§°", "å“ç‰Œ", "ç‰¹æ€§å‚æ•°", "è¯æ€§"}
            param_cols = [c for c in df.columns if c not in excluded]
            param_heats: dict[str, list[dict]] = {c: [] for c in param_cols}
            p_status = st.empty()
            p_prog = st.progress(0)
            p_status.text("æ­£åœ¨å¤„ç†å‚æ•°...")
            for idx, row in df.iterrows():
                vol = row["æœç´¢é‡"] if pd.notna(row["æœç´¢é‡"]) else 0
                for c in param_cols:
                    val = str(row[c]) if pd.notna(row[c]) else ""
                    for v in [v.strip() for v in val.split(",") if v.strip()]:
                        param_heats[c].append({"å‚æ•°å€¼": v, "æœç´¢é‡": vol})
                if (idx + 1) % step == 0 or idx == len(df) - 1:
                    p_prog.progress((idx + 1) / len(df))
            p_status.text("å‚æ•°å¤„ç†å®Œæˆ")
            p_prog.empty()
            p_status.empty()
            # Traffic structure
            traffic_df = df[["è¯æ€§", "æœç´¢é‡"]].groupby("è¯æ€§", as_index=False)["æœç´¢é‡"].sum()
            traffic_df = aggregate_top_n(traffic_df, "æœç´¢é‡", "è¯æ€§")
            # Workbook
            s_status = st.empty()
            s_prog = st.progress(0)
            s_status.text("æ­£åœ¨ç”ŸæˆExcelå·¥ä½œç°¿...")
            s_prog.progress(0.3)
            wb = Workbook()
            if "Sheet" in wb.sheetnames:
                wb.remove(wb["Sheet"])
            ws = wb.create_sheet("æºæ•°æ®")
            for r in dataframe_to_rows(df, index=False, header=True):
                ws.append(r)
            s_prog.progress(0.6)
            if not brand_df.empty:
                ws = wb.create_sheet("å“ç‰Œè¯æ‹†è§£")
                for r in dataframe_to_rows(brand_df, index=False, header=True):
                    ws.append(r)
            s_prog.progress(0.7)
            param_dfs: dict[str, pd.DataFrame] = {}
            active_params = [c for c in param_cols if param_heats[c]]
            for i, c in enumerate(active_params):
                heats = param_heats[c]
                if heats:
                    pdf = pd.DataFrame(heats).groupby("å‚æ•°å€¼", as_index=False)["æœç´¢é‡"].sum()
                    pdf = aggregate_top_n(pdf, "æœç´¢é‡", "å‚æ•°å€¼")
                    param_dfs[c] = pdf
                    clean = re.sub(r"[\/*?[\]]", "", c)[:31]
                    ws = wb.create_sheet(f"{clean}æ‹†è§£")
                    for r in dataframe_to_rows(pdf, index=False, header=True):
                        ws.append(r)
                s_prog.progress(0.7 + 0.3 * (i + 1) / max(1, len(active_params)))
            if not traffic_df.empty:
                ws = wb.create_sheet("å“ç±»æµé‡ç»“æ„")
                for r in dataframe_to_rows(traffic_df, index=False, header=True):
                    ws.append(r)
            s_prog.progress(1.0)
            s_status.text("å·¥ä½œç°¿ç”Ÿæˆå®Œæˆ")
            s_status.empty()
            s_prog.empty()
            buffer = save_workbook_to_buffer(wb)
            st.success("âœ… æ•°æ®å¤„ç†å®Œæˆï¼Œæ­£åœ¨ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
            st.markdown("### ğŸ“Š æ•°æ®å¯è§†åŒ–")
            if not brand_df.empty:
                pie_chart(brand_df, "æœç´¢é‡", "å“ç‰Œåç§°", "å“ç‰Œè¯æ‹†è§£")
            for c in param_cols:
                if c in param_dfs:
                    pie_chart(param_dfs[c], "æœç´¢é‡", "å‚æ•°å€¼", f"{c} å‚æ•°æœç´¢é‡åˆ†å¸ƒ")
            if not traffic_df.empty:
                pie_chart(traffic_df, "æœç´¢é‡", "è¯æ€§", "æµé‡ç»“æ„")
            st.divider()
            ts = get_timestamp()
            out_name = f"viz_result_{ts}.xlsx"
            out_path = os.path.join("/tmp", out_name)
            save_func = lambda: wb.save(out_path)
            render_download_section(
                buffer,
                out_name,
                "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                "ğŸ“¥ ä¸‹è½½å®Œæ•´æŠ¥è¡¨",
                "viz",
                has_save=True,
                save_func=save_func,
                save_path=out_path,
            )
